{"/":{"title":"ğŸé¦–é¡µ","content":"Obsidian + Quartz Publish Web HomePage\n\nHelloğŸ‘‹ï¼Œæœ¬é¡µé¢æä¾›äº†ä¸€ä¸ªç½‘ç»œè®¿é—®æˆ‘çš„ç¬”è®°çš„é€”å¾„ï¼Œä½¿ç”¨ Hugo æ­å»ºï¼ˆQuartzï¼‰ï¼Œç¬”è®°ä½¿ç”¨ Obsidian ç¼–å†™ã€‚\n\n## åŒé“¾çš„é˜…è¯»å»ºè®®\n- é€šè¿‡é¼ æ ‡æ‚¬æµ®é¢„è§ˆè¿›è¡Œä¸Šä¸‹æ–‡ä¸ä¸­æ–­çš„é˜…è¯»ã€‚\n- é€šè¿‡åº•éƒ¨å›¾å’ŒåŒå‘é“¾æ¥æ‰¾åˆ°æ›´å¤šæ„Ÿå…´è¶£çš„ã€‚\n- æƒ³æŸ¥æ‰¾ç›´æ¥ä½¿ç”¨æœç´¢æŒ‰é’®\n\nä¹Ÿå¯ä»¥æŸ¥çœ‹è¿™ä¸ªå¯¼èˆªï¼š[æ ‡ç­¾](/tags/)\n\n\nç›®å‰çš„å†™ä½œå·¥ä½œæµï¼š\n### å†™\nåœ¨ä»»æ„åœ°æ–¹éƒ½å¯ä»¥å†™ï¼Œæ‰“å¼€ä¸€ä¸ª obsidian ç›®æ ‡æ–‡ä»¶å¤¹å³å¯ã€‚\n\n### å‘å¸ƒåˆ°ç½‘é¡µ notes.abser.top\n1. é€šè¿‡ abserari/quartz è¿™ä¸ª repoï¼Œç›´æ¥ä½¿ç”¨ obsidian-git æ’ä»¶ï¼Œpush åˆ° quartz åº“ä¸­ã€‚\n2. æœ€åé€šè¿‡ git æäº¤åˆ° github è§¦å‘ action è‡ªåŠ¨æ„å»º\n3. æ„å»ºä½¿ç”¨ [[hugo-extended]]  [[hugo-obsidian]] å·¥å…·\n\n### åŒæ­¥åŠŸèƒ½\nç„¶åä½¿ç”¨ [remotely save](https://github.com/remotely-save/remotely-save) æ’ä»¶åŒæ­¥ï¼Œ\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%AD%A6%E4%B9%A0%E7%A8%80%E7%BC%BA%E7%9A%84%E6%8A%80%E8%83%BD":{"title":"ä¸ºä»€ä¹ˆå­¦ä¹ ç¨€ç¼ºçš„æŠ€èƒ½","content":"\u003e _åº”ç”¨å¼‚å¸¸å€¼ç®—æ³•çš„å›°éš¾æ­£æ˜¯è¿™æ ·åšçš„åŸå› ï¼æ›´å›°éš¾æ„å‘³ç€æ›´ç¨€æœ‰ã€‚_\n\nä¸ºäº†å¸®åŠ©æ‚¨å¼€å§‹åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œä»¥ä¸‹æ˜¯æˆ‘ä¸€éåˆä¸€éåœ°å›é¡¾çš„å››ä¸ªç»éªŒæ³•åˆ™ã€‚è™½ç„¶åªæœ‰å››ä¸ªï¼Œä½†å®ƒä»¬çš„å†²å‡»åŠ›å¾ˆå¤§ã€‚å®ƒä»¬æ˜¯æ•°ç™¾å°æ—¶æ€è€ƒå¦‚ä½•æ›´å¥½åœ°æ‰¾åˆ°ç¨€æœ‰å’Œæœ‰ä»·å€¼çš„æŠ€èƒ½çš„ç®€åŒ–ï¼š\n\n1.  **æˆä¸ºç¬¬ä¸€ä¸ªå­¦ä¹ æœ‰ä»·å€¼çš„æŠ€èƒ½çš„äººã€‚** è·Ÿè¸ªæ–°å…´ç§‘å­¦ã€æŠ€æœ¯ã€åº”ç”¨ç¨‹åºã€å·¥å…·ã€è¡Œä¸šå’Œé¢†åŸŸã€‚å½“å®ƒä»¬å‘ˆæŒ‡æ•°å¢é•¿æ—¶ï¼ŒèŠ±å‡ ä¸ªå°æ—¶æ¢ç´¢å®ƒä»¬ï¼Œçœ‹çœ‹æ˜¯å¦å€¼å¾—æŠ•å…¥æ›´å¤šæ—¶é—´ã€‚å®ƒå¯ä»¥å¸®åŠ©æ‚¨å°è¯•æ–°äº‹ç‰©ï¼Œè€Œä¸ä¼šå°†æ—¶é—´æµªè´¹åœ¨å˜æˆæ— ç”¨çš„äº‹ç‰©ä¸Šã€‚\n2.  **å­¦ä¹ å¾ˆéš¾çš„æœ‰ä»·å€¼çš„æŠ€èƒ½ã€‚** æ„¿æ„æŠ•èµ„äºç¦å¿Œã€ä¸æ˜¯è¶…çº§æ€§æ„Ÿçš„ã€è€—æ—¶ã€è´¹åŠ›ã€çœ‹èµ·æ¥æœ‰é£é™©æˆ–è¶…çº§æŠ€æœ¯æˆ–å­¦æœ¯çš„é¢†åŸŸã€‚\n3.  **å­¦ä¹ å…·æœ‰éšè—å¥½å¤„çš„å®è´µæŠ€èƒ½ã€‚** äººç±»æœ‰ä»·å€¼ç›²ç‚¹ã€‚ä»–ä»¬ä½ä¼°äº†å…·æœ‰æŠ½è±¡ã€é•¿æœŸå›æŠ¥çš„æŠ€èƒ½ï¼›å¾®æŠ€èƒ½ï¼›å…¶ä»–å­¦ç§‘çš„æŠ€èƒ½ï¼›å’Œè¢«é—å¿˜çš„ç»å…¸æ€æƒ³ã€‚\n4.  **é‡æ–°å®šä¹‰ä»·å€¼æ¯”å…±è¯†æ›´å¥½ã€‚** åœ¨æˆ‘ä»¬çš„èŒä¸šç”Ÿæ¶¯ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨æˆ‘ä»¬çš„æŠ€èƒ½ä¸ºä»–äººæœåŠ¡ã€‚å¯èƒ½æ˜¯å®¢æˆ·ã€è€æ¿ã€æˆ‘ä»¬çš„ç²‰ä¸ã€æ‹›è˜äººå‘˜æˆ–å…¶ä»–äººã€‚å¦‚æœæ‚¨èƒ½å¤Ÿæ¯”å…¶ä»–äººæ›´å¥½åœ°äº†è§£æ‚¨æ‰€æœåŠ¡çš„äººçš„æœªæ»¡è¶³éœ€æ±‚ï¼Œæ‚¨å°†èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³è¿™äº›éœ€æ±‚ã€‚\n\næˆ–è€…ï¼Œç®€è€Œè¨€ä¹‹ï¼Œè¯·è®°ä½ï¼š\n\n-   æˆä¸ºç¬¬ä¸€\n-   é¢å¯¹å›°éš¾\n-   å¯»æ‰¾éšè—çš„å¥½å¤„\n-   é‡æ–°å®šä¹‰ä»·å€¼\n\nä»¥ä¸Šæ˜¯ Michael Simomons çš„å­¦ä¹ ç¨€æœ‰æŠ€èƒ½çš„ç†è®ºï¼Œå…¶ä¸­æ€»ç»“çš„å‡ ç‚¹æˆ‘ä»¬åº”è¯¥å°è¯•çš„è§„åˆ™ï¼Œåœ¨ä»–çš„è§„åˆ™ä¸‹ï¼Œä»–æŒ‡å¯¼æœ‰å¦‚ä¸‹å­¦ä¹ èµ„æºï¼ˆéšä¸ªäººçš„æƒ…æ™¯å¯ä»¥æœ‰å˜ç§ï¼Œè¿™æ˜¯å½“ç„¶çš„ï¼‰\n![[2022-09-29#^cff4f1]] \n\n## ç¬¬ä¸€æ­¥ï¼Œè§£é‡Šï¼šæˆ‘ä»¬ç°åœ¨ä»è§„åˆ™å¼€å§‹è§£é‡Šï¼Œä»è€Œæ‰¾åˆ°æˆ‘ä»¬è‡ªå·±æƒ…æ™¯ä¸‹çš„å­¦ä¹ \n1. é¦–å…ˆï¼Œæ‰€æœ‰çš„æŠ€èƒ½éƒ½å¾ˆæœ‰ä»·å€¼ï¼Œç„¶åæˆ‘ä»¬è¦å»å¯»æ‰¾ç¨€ç¼ºæ€§çš„æŠ€èƒ½ã€‚è¿™ä¸ªå‰ææ˜¯æˆ‘ä»¬å…ˆæ‰¾åˆ°æœ‰ä»·å€¼çš„æŠ€èƒ½ï¼Œé€šè¿‡ä¸€ä¸ªæŒ‡æ•°å¢é•¿çš„æ¨¡å‹åˆ¤æ–­ä¸€ä¸ªäº‹ç‰©å‘å±•æ˜¯å¦è¶…å‡ºå¸¸è§„ï¼Œè¿™é€šå¸¸éƒ½ä»£è¡¨è¿™ä»¶äº‹æœ‰ä»·å€¼ã€‚é‚£æˆ‘ä»¬ä»¥ç¨‹åºå‘˜çš„è§†è§’ä¸¾ä¾‹ï¼Œ Web3 æ­£å¥½æ˜¯æ€¥éœ€æŠ€èƒ½ä¹‹ä¸€ï¼ˆå› ä¸ºéœ€æ±‚è€Œæœ‰ä»·å€¼ï¼‰ï¼Œç‰©è”ç½‘ï¼Œè¾¹ç¼˜æ–¹é¢çš„æŠ€èƒ½ä¹Ÿå¹¶é©¾é½é©±ã€‚\n2. ç„¶åæˆ‘ä»¬å»å¯»æ‰¾æŠ€èƒ½çš„**ç¨€ç¼ºæ€§**ï¼ï¼ˆå› ä¸ºç¨€ç¼ºæ€§å†³å®šä»·æ ¼ï¼‰è¿™ä¹Ÿæœ‰ä¸€ä¸ªæ¨¡å‹æ¥æè¿°ä»–ï¼Œå³è¢«ç¦æ­¢çš„ï¼Œæœªè¢«å¤§éƒ¨åˆ†äººå‘ç°çš„ï¼Œå¯èƒ½æ¯ç‡¥çš„ï¼Œè€—æ—¶ï¼Œè´¹åŠ›çš„ï¼Œæˆ–è€…çœ‹èµ·æ¥éå¸¸æœ‰é£é™©çš„ï¼Œä»¥åŠéå¸¸å­¦æœ¯çš„ï¼Œéå¸¸æŠ€æœ¯ä¸“ä¸šçš„é¢†åŸŸã€‚ï¼ˆæ¯•ç«Ÿä½ ä¸èƒ½æŒ‡æœ›ä¸€è¹´è€Œå°±çš„é¢†åŸŸæœ‰å¤šç¨€ç¼ºï¼Œä¿¡æ¯å·®æ˜¯å¾ˆéš¾ä¸€ç›´ä¿æŒçš„ï¼‰\n3. åŒæ—¶ä¸è¦å¿½è§†é•¿æœŸçš„**è¢«åŠ¨æŠ€èƒ½**ï¼Œå¤åˆ©ä¸»ä¹‰ï¼Œä»¥åŠä¸€äº›ç»å…¸æ€æƒ³ï¼Œä»–ä»¬ç”±äºé•¿æœŸå­˜åœ¨äºæˆ‘ä»¬çš„èº«è¾¹ï¼Œä¼šè¢«æˆ‘ä»¬çš„ä»·å€¼è¯„ä¼°å™¨å¿½è§†ã€‚ä»¥æŠ½è±¡çš„ï¼Œé•¿æœŸå›æŠ¥çš„æŠ€èƒ½ä¸ºä¾‹ï¼šå†™ç¬”è®°ï¼ŒåšæŒæ€»ç»“è¾“å‡ºï¼›å¾®æŠ€èƒ½ï¼Œä¸€äº›å·¥ä½œä¸Šçš„å°æŠ€å·§ï¼Œæ¯”å¦‚ç”µè„‘ä½¿ç”¨é¢†åŸŸä¸Šçš„ä¸€äº›å·¥å…·å¿«æ·é”®ï¼›**å…¶ä»–é¢†åŸŸçš„æŠ€èƒ½ï¼** å¾€å¾€ä¼šäº§ç”Ÿå·¨å¤§çš„**åŒ–å­¦ååº”**ï¼Œæ¯”å¦‚ç”Ÿç‰©å¯¹è®¡ç®—æœºé¢†åŸŸçš„å½±å“ï¼Œå½“ç„¶æˆ‘è¿˜æ˜¯å»ºè®®å­¦æ•°å­¦ï¼Œæ¯”å¦‚é‡‘èå‰²éŸ­èœèå…¥åŒºå—é“¾ï¼›ä»¥åŠä¸€äº›ç»å…¸æ€æƒ³ï¼šåˆ†æ²»å’Œä¸­é—´å±‚çš„æ€æƒ³è´¯å½»æ•´ä¸ªè®¡ç®—æœºç§‘å­¦ï¼Œç»å¸¸å‘ç°è®¡ç®—æœºçš„ä¸€äº›æ–°é¢†åŸŸåº”ç”¨äº†è€çš„ç»å…¸çš„æ€æƒ³ä»è€Œå¤§æ”¾å¼‚å½©ï¼Œæ¯”å¦‚æ·±åº¦å­¦ä¹ å•¦ï¼\n4. é‡æ–°å®šä¹‰ä»·å€¼è€Œéå…±è¯†ï¼Œè¿™å¥ç±»æ¯”å¯¹ä¸€ä¸ªè¡Œä¸šéœ€æ±‚çš„æ·±æŒ–ã€‚æŠ€èƒ½å¯ä»¥ä¸ºæ¯ä¸€ä¸ªä½¿ç”¨è€…æä¾›ç›¸åŒå½±å“çš„ç»“æœï¼Œä½†ç²¾å‡†çš„éœ€æ±‚åˆ†æå’ŒæŒ–æ˜ï¼Œèƒ½è®©æŸé¡¹æŠ€èƒ½å‘æ˜å‡ºæ›´å¤šçš„ä»·å€¼ï¼Œä»–æå‡äº†ä»·å€¼çš„åŒæ—¶ä¹Ÿæå‡äº†ç¨€ç¼ºæ€§ã€‚\n\nå½“ç„¶ï¼Œä»¥ä¸Šè§„åˆ™å…¶å®ä¸»è¦æ˜¯ä¸ªäººè§†è§’å‡ºå‘ï¼Œå¦‚ä½•å‘æŒ¥ä¸ªäººæœ€å¤§çš„å½±å“åŠ›çš„æ€è€ƒï¼Œä»å›¢é˜Ÿç­‰æ–¹å‘è¿˜èƒ½æœ‰æ›´å¤šï¼Œæ¯”å¦‚è§„æ¨¡æ•ˆåº”ï¼Œç„¶è€Œæˆ‘ä»¬å¸Œæœ›å°†è®¨è®ºèŒƒå›´é™åˆ¶åœ¨ä¸ªäººè§†è§’ä¸Šä»¥æœŸæä¾›ä¸€äº›åˆ‡å®çš„æŒ‡å¯¼ã€‚\n\n\té“ç†çš„æ‰©æ•£æˆæœ¬æ˜¯éå¸¸ä½çš„ï¼Œä½†æ˜¯è®©ä¸€ä¸ªäººç›¸ä¿¡è¿™ä¸ªé“ç†çš„æˆæœ¬æ˜¯æé«˜çš„ã€‚\n\n## ç¬¬äºŒæ­¥ åˆ†æå­¦ä¹ èµ„æºçš„æ–°å˜åŒ–\n| è€ƒè™‘ç¨€ç¼ºæ€§å‰                                 | å                                                           |\n| -------------------------------------------- | ------------------------------------------------------------ |\n| é˜…è¯»æœ€æ–°çš„ç•…é”€ä¹¦                             | å­¦æœ¯è®ºæ–‡                                                     |\n| æ—¶åˆ»æ£€æŸ¥ç¤¾äº¤åª’ä½“æŸ¥çœ‹æœ€å…·å½±å“åŠ›çš„äººçš„å‘è¨€     | é¢†åŸŸä¹‹å¤–çš„å­¦ç§‘ï¼ˆåŠ å¯†å­¦ã€ç»æµå­¦ï¼‰                             |\n| æ—¶åˆ»ä¿æŒå…³æ³¨è¡Œä¸šæœ€æ–°çš„æ–°é—»ï¼ˆæ‰€æœ‰äººéƒ½åœ¨å…³æ³¨ï¼‰ | è·å–ä¸€äº›ä¸“æœ‰æ•°æ®çš„æˆæƒå¹¶ç ”ç©¶                                 |\n|                                              | å’Œé¢†åŸŸå†…éƒ¨äººå£«å»ºç«‹æ·±åšçš„å…³ç³»ï¼ˆå¹¶ä¸”ä»–ä»¬å¾ˆå°‘å…¬å¼€åˆ†äº«è‡ªå·±çš„è§‚ç‚¹ |\n|                                              | ä¸€äº›æŠ½è±¡çš„å¿ƒç†æ¨¡å‹                                                             |\n\nå¯ä»¥çœ‹åˆ°å…¶ä¸­æ˜æ˜¾çš„å·®è·ï¼ŒåŒæ ·çš„ä¾‹å­è¿˜æœ‰å¾ˆå¤šï¼Œå°±ä¸ä¸€ä¸€åˆ—ä¸¾äº†ã€‚ç¬”è€…è¿™é‡Œæœ€æƒ³å¼ºè°ƒçš„è¿˜æ˜¯ç¨€ç¼ºä»£è¡¨è¿œç¦»å…±è¯†ï¼Œæ„å‘³ç€ä½ çš„é€‰æ‹©å‡ ä¹æ€»æ˜¯é”™çš„ï¼ˆå³ä½¿ä½ æ˜¯ä¸ªé¡¶å°–èªæ˜çš„äººï¼‰ï¼Œè¿™æ˜¯éœ€è¦è°¦è™šçš„æ€åº¦ï¼Œé¿å…ä¸€æ¬¡æŠ•å…¥è¿‡å¤šï¼Œéœ€è¦æœ‰è¶³å¤Ÿå¤šçš„è¯æ®ã€éªŒè¯ã€‚æ‰€ä»¥ä¿æŒè°¦è™šï¼Œç¦»ç¾¤æ‰èƒ½å°½é‡ä¿è¯ä¸ªäººçš„ç¨³å®šã€‚\n\nä»¥ç¨‹åºå‘˜çš„è§†è§’æ¥è®²ï¼Œå¯ä»¥å…ˆæœ‰è¿™å‡ æ¡ç»éªŒï¼š\n1. ä¸éœ€è¦çœ‹ä¹¦ï¼Œä¹¦å‡ ä¹æ€»æ˜¯è¿‡æ—¶çš„ï¼Œä¸ç¨€ç¼ºçš„ï¼Œæœ‰éœ€æ±‚çš„æŠ€èƒ½å­¦ä¹ é€”å¾„æˆ–è€…åŸºç¡€ï¼Œå°½é‡çœ‹å­¦æœ¯è®ºæ–‡ã€‚\n2. é¿å…å…³æ³¨é¢‡å…·å½±å“åŠ›çš„äººçš„ä¸€è¨€ä¸€è¡Œï¼Œé¿å…ä¸€ç›´å…³æ³¨ï¼Œè¦ä¹ˆæ·±æŒ–ï¼Œè¦ä¹ˆç•¥è¿‡ã€‚\n3. å¤šæ¥è§¦ä¸€äº›å…¶ä»–é¢†åŸŸçš„å­¦è¯†ï¼Œå½“å‰è¡Œä¸šçš„å…¶ä»–é¢†åŸŸï¼šå®‰å…¨ã€åº•å±‚ã€æŠ½è±¡è®ºè¯ï¼Œå…¶ä»–è¡Œä¸šçš„å„ä¸ªé¢†åŸŸï¼šå“²å­¦ï¼ˆæ¸¸æˆç†è®ºï¼‰ã€æ•°å­¦ã€ç»æµå­¦ã€ç­‰ç­‰ã€‚\n4. ä¸“æœ‰æ•°æ®å¹¶ä¸ä¸€å®šéœ€è¦æˆæƒï¼Œä¹Ÿéœ€è¦è‡ªå·±æ”¶é›†ï¼Œå½“ä½ çš„ä¸€äº›ç‹¬ç‰¹è§†è§’éœ€è¦éªŒè¯æ—¶ï¼Œå¯ä»¥è½»æ¾é€šè¿‡ç¼–ç¨‹ï¼ˆæœ€å¥½åˆæ³•ï¼‰çˆ¬å–éœ€è¦çš„ä¿¡æ¯åˆ†æéªŒè¯ï¼ˆå¦‚æœæœ‰ä¸€äº›å¾®æŠ€èƒ½æ¯”å¦‚æ•°æ®åˆ†æï¼Œä¼šè®©è¿™ä¸ªè¿‡ç¨‹æ›´é¡ºç†æˆç« ï¼‰\n5. ä¸ç”¨å…³æ³¨ç½‘çº¢ï¼Œè€Œæ˜¯è½¬è€Œå»ºç«‹æ·±åšçš„ä¸ªäººå…³ç³»ï¼Œè¿™å…¶å®åœ¨ä¸ªäººè®¤çŸ¥ï¼ˆèµ„æºç­‰ï¼‰ä¸è¶³çš„æƒ…å†µä¸‹çš„æœ€å¥½é€‰æ‹©ï¼Œè¯·å¯»æ‰¾è‡ªå·±èº«è¾¹çš„è¿™ç§äººï¼Œå¦‚æœæ¥è§¦ä¸åˆ°ï¼Œæˆ–è®¸ä½ åº”è¯¥æ¢ä¸€ä¸ªç¯å¢ƒã€‚\n6. ä¿æŒå†™ç¬”è®°çš„ä¹ æƒ¯ï¼ŒæŒç»­é”»ç‚¼è‡ªå·±çš„å¿ƒç†æ¨¡å‹ï¼Œè¿™ä¸ªè¿‡äºæŠ½è±¡ï¼Œä¸è¿‡å½“ä½ é˜…è¯»è¿™ç¯‡ç¬”è®°çš„æ—¶å€™ï¼Œå…¶å®å°±åœ¨åšè¿™æ ·çš„äº‹ã€‚å»¶ç»­å®ƒï¼\n\n## ä¸‹ä¸€æ­¥ï¼Œé€‰æ‹©\n\nç°åœ¨ï¼Œå®è·µä¸€ä¸‹è¿™ä¸ªç¨€ç¼ºæ€§çš„æ¨¡å‹ï¼Œæ‰¾åˆ°é€‚åˆä½ çš„æŠ€èƒ½ï¼Œè‡³å°‘ä¸ç›²ç›®çš„å­¦ä¹ äº†æ˜¯å—ï¼Ÿ","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E5%9C%A8RocksDB%E4%B8%8A%E5%88%9B%E5%BB%BACockroachDB%E9%A1%B9%E7%9B%AE":{"title":"ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨RocksDBä¸Šåˆ›å»ºCockroachDBé¡¹ç›®ï¼Ÿ","content":"https://www.cockroachlabs.com/blog/cockroachdb-on-rocksd/","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E4%BD%BF%E7%94%A8-quartz-%E6%89%98%E7%AE%A1-obsidian-%E5%88%B0%E7%BD%91%E7%BB%9C%E4%B8%8A":{"title":"ä½¿ç”¨ quartz æ‰˜ç®¡ obsidian åˆ°ç½‘ç»œä¸Š","content":"## Refer\nhttps://quartz.jzhao.xyz/notes/setup/\nhttps://quartz.jzhao.xyz/notes/obsidian/","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E6%97%85%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8":{"title":"æ—…è¡Œçš„æœ¬è´¨","content":"ç”¨å¼‚åŒ–æ€æƒ³å»æ€è€ƒï¼š\næ—…è¡Œçš„æœ¬è´¨æ˜¯\n-   ä¸ªäººè¿œç¦»ä»–ä»¬æ–‡åŒ–çš„çœŸå®é“è·¯\n-   æ·±å…¥æœªçŸ¥çš„æ·±å¤„é‡å¡‘è‡ªæˆ‘\n-   ç„¶åå°†è¿™ç§å­¦ä¹ å¸¦å›ä»–ä»¬çš„æ–‡åŒ–ï¼Œè¿™æ ·å®ƒå°±å¯ä»¥å‘å±•","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E6%B8%85%E7%90%86-GIt-%E4%B8%AD%E7%9A%84%E5%8E%86%E5%8F%B2%E6%96%87%E4%BB%B6":{"title":"æ¸…ç† GIt ä¸­çš„å†å²æ–‡ä»¶","content":"```\ngit filter-branch --force --index-filter 'git rm --cached --ignore-unmatch path-to-your-remove-file' --prune-empty --tag-name-filter cat -- --all\n```\n\nå…¶ä¸­,Â path-to-your-remove-fileÂ å°±æ˜¯ä½ è¦åˆ é™¤çš„æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„(ç›¸å¯¹äºgitä»“åº“çš„è·Ÿç›®å½•), æ›¿æ¢æˆä½ è¦åˆ é™¤çš„æ–‡ä»¶å³å¯. æ³¨æ„ä¸€ç‚¹ï¼Œè¿™é‡Œçš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼Œéƒ½ä¸èƒ½ä»¥ '/' å¼€å¤´ï¼Œå¦åˆ™æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ä¼šè¢«è®¤ä¸ºæ˜¯ä» git çš„å®‰è£…ç›®å½•å¼€å§‹ã€‚\n\nå¦‚æœä½ è¦åˆ é™¤çš„ç›®æ ‡ä¸æ˜¯æ–‡ä»¶ï¼Œè€Œæ˜¯æ–‡ä»¶å¤¹ï¼Œé‚£ä¹ˆè¯·åœ¨ `git rm --cached` å‘½ä»¤åé¢æ·»åŠ Â -rÂ å‘½ä»¤ï¼Œè¡¨ç¤ºé€’å½’çš„åˆ é™¤ï¼ˆå­ï¼‰æ–‡ä»¶å¤¹å’Œæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶ï¼Œç±»ä¼¼äº `rm -rf` å‘½ä»¤ã€‚\n\næ›´å¤šè¯·å‚è€ƒï¼š[ https://help.github.com/articles/remove-sensitive-data](https://help.github.com/articles/remove-sensitive-data)","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E8%8B%B1%E9%9B%84%E4%B9%8B%E6%97%85":{"title":"è‹±é›„ä¹‹æ—…","content":"\nè‹±é›„ä¹‹æ—…å°±æ˜¯äººç±»ç¤¾ä¼šä¸­çš„æœ€å¸¸è§çš„åŸå‹ç¥è¯ã€‚\n\n![[Pasted image 20220929203142.png]]![[Pasted image 20220929203529.png]]\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E9%80%90%E6%AD%A5%E6%8F%8F%E8%BF%B0%E4%B8%80%E4%B8%AA%E6%96%B0%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%B9%E5%BC%8F":{"title":"é€æ­¥æè¿°ä¸€ä¸ªæ–°æ¨¡å‹çš„æ–¹å¼","content":"é€šè¿‡æè¿°ä¸€ä¸ªä¸œè¥¿ï¼Œèƒ½æä¾›ä»€ä¹ˆï¼Œèƒ½åšä»€ä¹ˆæ¥æ„ŸçŸ¥ä»–ã€‚\n\nä¸è¦æ€¥ç€ä¸‹å®šä¹‰ï¼Œè¿™ä¼šè®©è‡ªå·±ä¸§å¤±æ±‚çŸ¥æ¬²ã€‚\n\næœ‰ç‚¹åƒç¼–ç¨‹é¢†åŸŸçš„[[é¸­å­ç±»å‹]]çš„å»¶ä¼¸ã€‚","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/%E9%B8%AD%E5%AD%90%E7%B1%BB%E5%9E%8B":{"title":"é¸­å­ç±»å‹","content":"åŒ Duck-Type\n\nåŸç†æ˜¯ï¼šåªè¦ä¸€ä¸ªä¸œè¥¿ä¼šâ€œå˜å˜â€å«ï¼Œå°±è®¤ä¸ºå®ƒæ˜¯ä¸€åªé¸­å­ã€‚\n\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/Dockerfile-%E5%A4%9A%E8%A1%8C%E8%84%9A%E6%9C%AC":{"title":"Dockerfile å¤šè¡Œè„šæœ¬","content":"```\n# syntax = docker/dockerfile:1.4\nFROM debian \n-RUN apt-get \u0026\u0026 \\ \n- apt-get install -y vim \n +RUN \u003c\u003ceot bash \n+ apt-get update \n+ apt-get install -y vim \neot\n```","lastmodified":"2022-10-11T11:25:57.630335428Z","tags":null},"/Golang":{"title":"","content":"","lastmodified":"2022-10-11T11:25:57.630335428Z","tags":null},"/LSMs":{"title":"LSMs","content":"åŸºäºæ—¥å¿—ç»“æ„çš„åˆå¹¶æ ‘\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/LVM-%E9%87%8D%E5%90%AF%E9%9C%80%E8%A6%81%E9%87%8D%E6%96%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E5%90%A6%E5%88%99%E4%B8%A2%E5%A4%B1-vg-%E8%AE%BE%E5%A4%87%E7%9A%84%E9%97%AE%E9%A2%98":{"title":"LVM é‡å¯éœ€è¦é‡æ–°åˆå§‹åŒ–å¦åˆ™ä¸¢å¤± vg è®¾å¤‡çš„é—®é¢˜","content":"https://www.aboutyun.com/thread-16065-1-1.html\n\nè®¾ç½®Â Â å¼€æœºæŒ‚è½½ ï¼Œokäº†  \n  \ncat /etc/rc.d/rc.local |grep cinder-volumes || echo 'losetup -f /var/lib/cinder/cinder-volumes \u0026\u0026 vgchange -a y cinder-volumes ' \u003e\u003e /etc/rc.d/rc.local\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/PriceOps":{"title":"PriceOps","content":"ä»€ä¹ˆæ˜¯ PriceOps ?\nè§£é‡Šç½‘å€ï¼š https://priceops.org/\n\nåšä¸€ä¸‹ç¬”è®°ï¼š\n\n\tPriceOps éƒ¨åˆ†å®šä¹‰\n\t\n\tPriceOps æ˜¯ä¸€ç§å®ç°è¿­ä»£å’Œçµæ´»æ€§çš„æ–¹æ³•ã€‚å®ƒæè¿°äº†ä¸€ç»„é€šè¿‡æœ‰æ•ˆç®¡ç†å›ºæœ‰å¤æ‚æ€§æ¥ä¿ƒè¿›å®šä»·æ¨¡å‹æ¢ç´¢çš„å®ç°å±æ€§ã€‚å°†æ­¤è§†ä¸ºä¸€ç»„æ¶æ„è“å›¾å’Œæœ€ä½³å®è·µï¼Œå¯ä»¥å¸®åŠ©æ‚¨æŒç»­å¼€å‘å’Œå®Œå–„æ‚¨çš„å®šä»·åŸºç¡€æ¶æ„ã€‚\n\t\n\tPriceOps_ä¸æ˜¯_å…³äºä»»ä½•ç‰¹å®šäº§å“åº”å¦‚ä½•å®šä»·æˆ–å¦‚ä½•ç¡®å®šæ­¤ç±»ä»·æ ¼çš„è§„å®šæ€§æŒ‡å—ã€‚ç›¸åï¼Œå®ƒæ˜¯å¦‚ä½•å®æ–½å®šä»·æ¨¡å‹ä»¥æœ€å¤§é™åº¦åœ°æé«˜çµæ´»æ€§å’Œç¨³å®šæ€§çš„æŒ‡å—ã€‚\n\næˆ‘ç†è§£å¦‚ä¸‹ï¼š\n\nå°†å®šä»·æ¨¡å‹é€šè¿‡ä»£ç æè¿°å‡ºæ¥ï¼Œç°åœ¨æ˜¯ jsonï¼Œå› ä¸ºæœ‰ code æå¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼Œæ‰€ä»¥å¯èƒ½å¯ä»¥ä»ä¸­çœ‹å‡ºå®šä»·å¯¹äºäº§å“çš„å½±å“æœ‰å“ªäº›ã€‚ä»è€Œåšå‡ºè°ƒæ•´ã€‚\n\nåˆ—å‡ºäº†æ”¯æ’‘æ¨¡å‹çš„äº”ä¸ªæ”¯æŸ±ï¼ˆè‹±æ–‡ï¼š[[pillar]])\n\n1. å®šä»·æ¨¡å‹çš„å®šä¹‰ï¼šä¾‹å¦‚ç‰ˆæœ¬åŒ–ä»£è¡¨ä¸ä¼šå½±å“ä¹‹å‰çš„ç”¨æˆ·\n2. ç”¨æˆ·çš„æ—¶é—´è¡¨ï¼šè¿™æ ·ä¸€ä¸ªå®šä»·è®¡åˆ’å°±å¯ä»¥è§„å®šåœ¨å“ªäº›æ—¶é—´é‡Œé¢å¯ä»¥ä½¿ç”¨å“ªäº›åŠŸèƒ½ï¼Œå¹¶èƒ½æœ‰å¤šå°‘ä½¿ç”¨é‡\n3. è®¡é‡ç³»ç»Ÿï¼šç”¨äºæ”¶é›†æ‰€æœ‰ç”¨æˆ·ä½¿ç”¨ä¿¡æ¯ï¼Œä¸€ä¸ªæ•°æ®ä¸­å¿ƒä¸­å­˜å‚¨ï¼Œæ¥å¸®åŠ©å®šä»·æ¨¡å‹çš„æ›´æ–°\n4. æƒé™æ£€æŸ¥ï¼šè¿™æ ·åº”ç”¨ç¨‹åºä»£ç åªéœ€è¦æä¾›åŠŸèƒ½ï¼Œä¸éœ€è¦çŸ¥é“åŠŸèƒ½åœ¨å“ªäº›è®¡åˆ’ä¸­ã€‚\n5. PriceOps å·¥å…·ï¼šä¸ºä»¥ä¸Šè¡Œä¸ºæä¾›æ“ä½œçš„å·¥å…·\n\næˆ‘å¾ˆå–œæ¬¢è¿™ç§ [[é€æ­¥æè¿°ä¸€ä¸ªæ–°æ¨¡å‹çš„æ–¹å¼]]ï¼Œå®ƒè¿˜èƒ½æŒç»­è¿­ä»£ä¸€ä¸ªä¸œè¥¿å®šä¹‰ï¼Œå¦‚æœä¸€å¼€å§‹å°±ä¸‹ç»“è®ºï¼Œè¿™ä¸ªæ¨¡å‹å°±è€æ­»äº†ã€‚","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/Pricing-as-Code":{"title":"Pricing as Code","content":"ä¸€ç§å¾ˆæ–°çš„ä¸œè¥¿.\næ¦‚å¿µæ¨¡å‹: [[PriceOps]]\nç¤ºä¾‹äº§å“ï¼š[[Tier]]  https://www.tier.run/","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/Tier":{"title":"Tier","content":"https://www.tier.run/\nç†å¿µï¼š [[Pricing as Code]] ã€[[PriceOps]] ","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/Configmap-Secret-Manager":{"title":"Configmap/Secret Manager","content":"## Configmap/Secret Manager\n\n\u003ca name=\"YjhpG\"\u003e\u003c/a\u003e\n## ReadLink\n\n- [configmap manager](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/configmap/configmap_manager.go)\n- [pkg/kubelet/secret/secret_manager.go](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/secret/secret_manager.go)\n\u003ca name=\"GuGtv\"\u003e\u003c/a\u003e\n\n## Configmap Manager\n\n```go\n// Manager interface provides methods for Kubelet to manage ConfigMap.\ntype Manager interface {\n    // Get configmap by configmap namespace and name.\n    GetConfigMap(namespace, name string) (*v1.ConfigMap, error)\n    \n    // WARNING: Register/UnregisterPod functions should be efficient,\n    // i.e. should not block on network operations.\n    \n    // RegisterPod registers all configmaps from a given pod.\n    RegisterPod(pod *v1.Pod)\n    \n    // UnregisterPod unregisters configmaps from a given pod that are not\n    // used by any other registered pod.\n    UnregisterPod(pod *v1.Pod)\n}\n```\n\næ¥å£éå¸¸ç®€å•ã€‚\n\n1. GetConfigMap ï¼š é€šè¿‡ namespace å’Œ name è·å–å¯¹åº” ConfigMap å¯¹è±¡ã€‚\n1. RegisterPod(pod *v1.Pod)ï¼šæŠŠæŒ‡å®š Pod å¯¹è±¡ yaml æŒ‡å®šçš„ configmap æ³¨å†Œåˆ° Controller ä¸­ç®¡ç†\n1. UnregisterPod(pod *v1.Pod)ï¼šæŠŠæŒ‡å®š Pod å¯¹è±¡ yaml æŒ‡å®šçš„ configmap ä» Controller ä¸­æ³¨å†Œç®¡ç†ä¸­åˆ é™¤ï¼Œæ³¨æ„ ConfigMap éœ€è¦æ²¡æœ‰ä»»ä½•å…¶ä»–å·²æ³¨å†Œçš„ Pod å¼•ç”¨ï¼ˆå³æ— è¢«ä¾èµ–é¡¹ï¼‰æ‰å¯ä»¥åˆ é™¤\n\nå½“å‰ä»£ç ä¸­æœ‰ä¸¤ç§ manager çš„å®ç°\n\n-`NewCachingConfigMapManager(kubeClient clientset.Interface, getTTL manager.GetObjectTTLFunc) Manager`ï¼šè¯¥å®ç°æœ‰ä¸¤ç‚¹é€»è¾‘\n   - å½“ä¸€ä¸ª Pod åˆ›å»ºæˆ–è€…æ›´æ–°æ—¶ï¼Œæ‰€æœ‰çš„ configmap ç¼“å­˜éƒ½å¤±æ•ˆã€‚\n   -  GetObject() è°ƒç”¨é¦–å…ˆä»æœ¬åœ°ç¼“å­˜è·å–ï¼Œå¤±è´¥åˆ™è®¿é—® APISever å¹¶åˆ·æ–° configmap çš„ç¼“å­˜ã€‚\n\n```go\n// NewCachingConfigMapManager creates a manager that keeps a cache of all configmaps\n// necessary for registered pods.\n// It implement the following logic:\n// - whenever a pod is create or updated, the cached versions of all configmaps\n//   are invalidated\n// - every GetObject() call tries to fetch the value from local cache; if it is\n//   not there, invalidated or too old, we fetch it from apiserver and refresh the\n//   value in cache; otherwise it is just fetched from cache\nfunc NewCachingConfigMapManager(kubeClient clientset.Interface, getTTL manager.GetObjectTTLFunc) Manager {\n\tgetConfigMap := func(namespace, name string, opts metav1.GetOptions) (runtime.Object, error) {\n\t\treturn kubeClient.CoreV1().ConfigMaps(namespace).Get(context.TODO(), name, opts)\n\t}\n\tconfigMapStore := manager.NewObjectStore(getConfigMap, clock.RealClock{}, getTTL, defaultTTL)\n\treturn \u0026configMapManager{\n\t\tmanager: manager.NewCacheBasedManager(configMapStore, getConfigMapNames),\n\t}\n}\n```\n\n- `NewWatchingConfigMapManager(kubeClient clientset.Interface, resyncInterval time.Duration) Manager`ï¼š\n   - å½“ä¸€ä¸ª Pod åˆ›å»ºæˆ–è€…æ›´æ–°æ—¶ï¼Œä¼šå¯¹æŒ‡å®šè¯¥ Pod å¼•ç”¨çš„èµ„æºï¼Œå¹¶ä¸”è¯¥èµ„æºæœªè¢«å…¶ä»– Pod å¼•ç”¨è¿›è¡Œç‹¬ç«‹çš„ watchã€‚\n   - GetObject() è°ƒç”¨é¦–å…ˆä»æœ¬åœ°ç¼“å­˜è·å–\n\n```go\n// NewWatchingConfigMapManager creates a manager that keeps a cache of all configmaps\n// necessary for registered pods.\n// It implements the following logic:\n// - whenever a pod is created or updated, we start individual watches for all\n//   referenced objects that aren't referenced from other registered pods\n// - every GetObject() returns a value from local cache propagated via watches\nfunc NewWatchingConfigMapManager(kubeClient clientset.Interface, resyncInterval time.Duration) Manager {\n\tlistConfigMap := func(namespace string, opts metav1.ListOptions) (runtime.Object, error) {\n\t\treturn kubeClient.CoreV1().ConfigMaps(namespace).List(context.TODO(), opts)\n\t}\n\twatchConfigMap := func(namespace string, opts metav1.ListOptions) (watch.Interface, error) {\n\t\treturn kubeClient.CoreV1().ConfigMaps(namespace).Watch(context.TODO(), opts)\n\t}\n\tnewConfigMap := func() runtime.Object {\n\t\treturn \u0026v1.ConfigMap{}\n\t}\n\tisImmutable := func(object runtime.Object) bool {\n\t\tif configMap, ok := object.(*v1.ConfigMap); ok {\n\t\t\treturn configMap.Immutable != nil \u0026\u0026 *configMap.Immutable\n\t\t}\n\t\treturn false\n\t}\n\tgr := corev1.Resource(\"configmap\")\n\treturn \u0026configMapManager{\n\t\tmanager: manager.NewWatchBasedManager(listConfigMap, watchConfigMap, newConfigMap, isImmutable, gr, resyncInterval, getConfigMapNames),\n\t}\n}\n\n```\n\n\u003ca name=\"gEtqm\"\u003e\u003c/a\u003e\n## Secret Manager\n\nsecret manager é™¤äº†èµ„æºç±»å‹å’Œ configmap ä¸ä¸€æ ·ï¼Œå…¶ä»–é€»è¾‘ç›¸åŒï¼Œæ‰€ä»¥ä»…åˆ—å‡ºä¸¤ç§ secret manager çš„åˆå§‹åŒ–å‡½æ•°ã€‚\u003cbr /\u003e[/](https://sourcegraph.com/github.com/kubernetes/kubernetes)[pkg /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg)[kubelet /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet)[secret /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/secret)[secret_manager.go](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/secret/secret_manager.go)\n\n```go\n// NewCachingSecretManager creates a manager that keeps a cache of all secrets\n// necessary for registered pods.\n// It implements the following logic:\n// - whenever a pod is created or updated, the cached versions of all secrets\n//   are invalidated\n// - every GetObject() call tries to fetch the value from local cache; if it is\n//   not there, invalidated or too old, we fetch it from apiserver and refresh the\n//   value in cache; otherwise it is just fetched from cache\nfunc NewCachingSecretManager(kubeClient clientset.Interface, getTTL manager.GetObjectTTLFunc) Manager {\n\tgetSecret := func(namespace, name string, opts metav1.GetOptions) (runtime.Object, error) {\n\t\treturn kubeClient.CoreV1().Secrets(namespace).Get(context.TODO(), name, opts)\n\t}\n\tsecretStore := manager.NewObjectStore(getSecret, clock.RealClock{}, getTTL, defaultTTL)\n\treturn \u0026secretManager{\n\t\tmanager: manager.NewCacheBasedManager(secretStore, getSecretNames),\n\t}\n}\n\n// NewWatchingSecretManager creates a manager that keeps a cache of all secrets\n// necessary for registered pods.\n// It implements the following logic:\n// - whenever a pod is created or updated, we start individual watches for all\n//   referenced objects that aren't referenced from other registered pods\n// - every GetObject() returns a value from local cache propagated via watches\nfunc NewWatchingSecretManager(kubeClient clientset.Interface, resyncInterval time.Duration) Manager {\n\tlistSecret := func(namespace string, opts metav1.ListOptions) (runtime.Object, error) {\n\t\treturn kubeClient.CoreV1().Secrets(namespace).List(context.TODO(), opts)\n\t}\n\twatchSecret := func(namespace string, opts metav1.ListOptions) (watch.Interface, error) {\n\t\treturn kubeClient.CoreV1().Secrets(namespace).Watch(context.TODO(), opts)\n\t}\n\tnewSecret := func() runtime.Object {\n\t\treturn \u0026v1.Secret{}\n\t}\n\tisImmutable := func(object runtime.Object) bool {\n\t\tif secret, ok := object.(*v1.Secret); ok {\n\t\t\treturn secret.Immutable != nil \u0026\u0026 *secret.Immutable\n\t\t}\n\t\treturn false\n\t}\n\tgr := corev1.Resource(\"secret\")\n\treturn \u0026secretManager{\n\t\tmanager: manager.NewWatchBasedManager(listSecret, watchSecret, newSecret, isImmutable, gr, resyncInterval, getSecretNames),\n\t}\n}\n```\n\n\u003ca name=\"RX3SN\"\u003e\u003c/a\u003e\n## cache_based_manager\n[/](https://sourcegraph.com/github.com/kubernetes/kubernetes)[pkg /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg)[kubelet /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet)[util /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/util)[manager /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/util/manager)[cache_based_manager.go](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/util/manager/cache_based_manager.go)\n\n```go\n// cacheBasedManager keeps a store with objects necessary\n// for registered pods. Different implementations of the store\n// may result in different semantics for freshness of objects\n// (e.g. ttl-based implementation vs watch-based implementation).\ntype cacheBasedManager struct {\n    objectStore          Store\n\tgetReferencedObjects func(*v1.Pod) sets.String\n\n\tlock           sync.Mutex\n\tregisteredPods map[objectKey]*v1.Pod\n}\n```\n\nè¯¥ manager ä»£ç ä½äº  [/](https://sourcegraph.com/github.com/kubernetes/kubernetes)[pkg /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg)[kubelet /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet)[util /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/util)[manager /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/util/manager)[cache_based_manager.go](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/util/manager/cache_based_manager.go)ï¼Œå±äºé€šç”¨çš„ Manager ç»“æ„ä½“å·¥å…·ï¼Œç”¨äºä¿ç•™æ³¨å†Œçš„  Pod æ‰€å¿…è¦å¼•ç”¨çš„ kubernetes å¯¹è±¡ï¼ˆobjectsï¼‰\u003cbr /\u003eå¦‚ä½•åšåˆ°çš„å‘¢ï¼Ÿ\u003cbr /\u003eé€šè¿‡ getReferencedObjects å­—æ®µï¼Œä¸€ä¸ªå¯ä»¥ä¼ å…¥çš„æˆå‘˜å‡½æ•°ï¼Œè‡ªå®šä¹‰å®ç°ç”¨äºä» v1.Pod å¯¹è±¡ä¸­è·å–åˆ°å¯¹åº”å¯¹è±¡ï¼ˆæˆ–ä¸€ç»„å¯¹è±¡ï¼‰çš„ nameã€‚æµç¨‹å¦‚ä¸‹ï¼š\n\n```go\nfunc (c *cacheBasedManager) RegisterPod(pod *v1.Pod) {\n    // 1. è·å–åå­—\n\tnames := c.getReferencedObjects(pod)\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n    // 2. ç»™æ¯ä¸€ä¸ªåå­—å’Œ pod çš„å‘½åç©ºé—´ä¸€èµ·æ·»åŠ åˆ° c.objectStore ä¸­å­˜å‚¨\n\tfor name := range names {\n\t\tc.objectStore.AddReference(pod.Namespace, name)\n\t}\n    // 3. æ£€æŸ¥æ˜¯å¦ä¹‹å‰å·²ç»æ³¨å†Œäº†è¯¥ Pod\n\tvar prev *v1.Pod\n\tkey := objectKey{namespace: pod.Namespace, name: pod.Name, uid: pod.UID}\n\tprev = c.registeredPods[key]\n    // 4. ç”¨æ–°æ³¨å†Œçš„ pod æ›¿æ¢ä¹‹å‰å­˜å‚¨çš„æ³¨å†Œ Pod çš„ä¿¡æ¯.\n\tc.registeredPods[key] = pod\n    // 5. åˆ é™¤æ—§ Pod åœ¨ c.objectStore ä¸­çš„å¼•ç”¨ä¿¡æ¯,è¿™æ˜¯å› ä¸ºåœ¨ä¸Šé¢ç¬¬äºŒæ­¥ Add åˆ° c.objectStore\n    // ä¸­æ—¶,è¿™äº›èµ„æºçš„å¼•ç”¨æ¬¡æ•°åˆæ–°å¢äº†ä¸€æ¬¡,ä½†å®é™…ä¸Šåªæ˜¯åŒä¸€ä¸ª Pod çš„å¼•ç”¨,è‡ªç„¶éœ€è¦åˆ é™¤,å½“ç„¶,ä¹Ÿæœ‰\n    // å¯èƒ½æ–° Pod å·²ç»ä¸å†å¼•ç”¨ç›®æ ‡èµ„æºäº†, Delete å‡½æ•°åœ¨ä¸‹é¢ä¹Ÿå¤„ç†è¿™ä¸ªæƒ…å†µ\n\tif prev != nil {\n\t\tfor name := range c.getReferencedObjects(prev) {\n\t\t\t// On an update, the .Add() call above will have re-incremented the\n\t\t\t// ref count of any existing object, so any objects that are in both\n\t\t\t// names and prev need to have their ref counts decremented. Any that\n\t\t\t// are only in prev need to be completely removed. This unconditional\n\t\t\t// call takes care of both cases.\n\t\t\tc.objectStore.DeleteReference(prev.Namespace, name)\n\t\t}\n\t}\n}\n```\n\n1. è·å–åå­—\n1. ç»™æ¯ä¸€ä¸ªåå­—å’Œ pod çš„å‘½åç©ºé—´ä¸€èµ·æ·»åŠ åˆ° c.objectStore ä¸­å­˜å‚¨\n1. æ£€æŸ¥æ˜¯å¦ä¹‹å‰å·²ç»æ³¨å†Œäº†è¯¥ Pod\n1. ç”¨æ–°æ³¨å†Œçš„ pod æ›¿æ¢ä¹‹å‰å­˜å‚¨çš„æ³¨å†Œ Pod çš„ä¿¡æ¯.\n5. åˆ é™¤æ—§ Pod åœ¨ c.objectStore ä¸­çš„å¼•ç”¨ä¿¡æ¯,è¿™æ˜¯å› ä¸ºåœ¨ä¸Šé¢ç¬¬äºŒæ­¥ Add åˆ° c.objectStore ä¸­æ—¶,è¿™äº›èµ„æºçš„å¼•ç”¨æ¬¡æ•°åˆæ–°å¢äº†ä¸€æ¬¡,ä½†å®é™…ä¸Šåªæ˜¯åŒä¸€ä¸ª Pod çš„å¼•ç”¨,è‡ªç„¶éœ€è¦åˆ é™¤,å½“ç„¶,ä¹Ÿæœ‰å¯èƒ½æ–° Pod å·²ç»ä¸å†å¼•ç”¨ç›®æ ‡èµ„æºäº†, Delete å‡½æ•°åœ¨ä¸‹é¢ä¹Ÿå¤„ç†è¿™ä¸ªæƒ…å†µ\n\n\u003ca name=\"aQgQM\"\u003e\u003c/a\u003e\n### ttl ObjectStore\n\ncache_based çš„ objectStore é€šè¿‡ ttl è®¾ç½®ç¼“å­˜æœ‰æ•ˆæœŸã€‚\n\u003ca name=\"qzaxL\"\u003e\u003c/a\u003e\n\n## watch_based_manager\n[/](https://sourcegraph.com/github.com/kubernetes/kubernetes)[pkg /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg)[kubelet /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet)[util /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/util)[manager /](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/tree/pkg/kubelet/util/manager)[watch_based_manager.go](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/util/manager/watch_based_manager.go)\u003cbr /\u003eå¯ä»¥çœ‹åˆ°ï¼Œwatch_based_manager æœ€åä½¿ç”¨äº† NewCacheBasedManager ï¼Œæ‰€ä»¥ watch_based_manager  å’Œ cache_based_manager ä¸åŒçš„æ˜¯ ObjectStore å­—æ®µã€‚\n\n\n```go\n// NewWatchBasedManager creates a manager that keeps a cache of all objects\n// necessary for registered pods.\n// It implements the following logic:\n// - whenever a pod is created or updated, we start individual watches for all\n//   referenced objects that aren't referenced from other registered pods\n// - every GetObject() returns a value from local cache propagated via watches\nfunc NewWatchBasedManager(\n\tlistObject listObjectFunc,\n\twatchObject watchObjectFunc,\n\tnewObject newObjectFunc,\n\tisImmutable isImmutableFunc,\n\tgroupResource schema.GroupResource,\n\tresyncInterval time.Duration,\n\tgetReferencedObjects func(*v1.Pod) sets.String) Manager {\n\n\t// If a configmap/secret is used as a volume, the volumeManager will visit the objectCacheItem every resyncInterval cycle,\n\t// We just want to stop the objectCacheItem referenced by environment variables,\n\t// So, maxIdleTime is set to an integer multiple of resyncInterval,\n\t// We currently set it to 5 times.\n\tmaxIdleTime := resyncInterval * 5\n\n\t// TODO propagate stopCh from the higher level.\n\tobjectStore := NewObjectCache(listObject, watchObject, newObject, isImmutable, groupResource, clock.RealClock{}, maxIdleTime, wait.NeverStop)\n\treturn NewCacheBasedManager(objectStore, getReferencedObjects)\n}\n```\n\nwatch_based_manager  é€šè¿‡ watch è€Œä¸æ˜¯ç®€å•çš„ ttl å»ç¡®è®¤æˆ–è€…åˆ·æ–°ç¼“å­˜ã€‚\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/How-Cloud-Develop-Kit-from-Google-designed-the-docstore-interface":{"title":"How Cloud Develop Kit from Google designed the docstore interface","content":"\n## How Cloud Develop Kit from Google designed the docstore interface\n\n\u003ca name=\"ljgKZ\"\u003e\u003c/a\u003e\n## Refer\n- [Docstore Â· Go CDK](https://gocloud.dev/howto/docstore/)\n- [urls.go - google/go-cloud - Sourcegraph](https://sourcegraph.com/github.com/google/go-cloud@master/-/blob/docstore/mongodocstore/urls.go)\n- [driver.go - Go](https://cs.opensource.google/go/go/+/refs/tags/go1.18.3:src/database/sql/driver/driver.go)\n\u003ca name=\"Eu7vN\"\u003e\u003c/a\u003e\n\n## Design objectives: \n\n**through the abstraction layer, we can mask differences, provide services in a standardized way, and configure business applications through description files. **\n\n**Provides design ideas and guidelines for applications that use document storage. **\n\u003ca name=\"yaqn6\"\u003e\u003c/a\u003e\n## Intro\ncommon in MongoDB [document Storage](https://en.wikipedia.org/wiki/Document-oriented_database) provides an abstraction layer. \n\nDocument Storage is a service that stores data in semi-structured JSON-like documents. These documents are grouped into collections. Like other NoSQL databases, document storage is modeless. \n\nThe design needs to support adding, retrieving, modifying, and deleting documents. \ndocstore Driver implementation of various services, including cloud and local solutions. You can develop applications locally and then reconfigure them to multiple cloud providers with minimal initialization. \n\u003ca name=\"FCVI2\"\u003e\u003c/a\u003e\n## è®¾è®¡\n\u003ca name=\"fg6xL\"\u003e\u003c/a\u003e\n### Structuring Portable Code \nStructuring Portable Code the non-interface design imitates the database/SQL package of golang and wraps the existing common logic into the structure. The internal fields of the structure are driver interfaces. The method provided externally is the method corresponding to the structure rather than the implementation of the direction provided driver.\n\n\u003e The advantage of this design is that there is no need to implement general logic processing for each interface, and the code can be transplanted. In some cases, you only need to add and modify methods on the structure and do not need to destroy the method design in the interface. You can also mask some assertion logic. When switching different drivers, users do not need to determine the implementation of some optional interfaces.\n\n[Structuring Portable Code Â· Go CDK](https://gocloud.dev/concepts/structure/)\n\n[sql package - database/sql - Go Packages](https://pkg.go.dev/database/sql#DB)\n\n![[blogs/Pasted image 20221011180052.png]]\n\n\u003cbr /\u003eCode like belowï¼š\n```go\n// Define\ntype DB interface{\n    Exec(sql string)error\n}\n\n// Realize\ntype mysql struct {}\nfunc (m *mysql) Exec(sql string) error {return nil}\n\n// Execute\nsql.Database.Exec(\"\")\n```\n```go\n// package and structure\npackage sql\n\ntype DB struct {\n    driver driver.DB\n}\n\n// higher level logic\nfunc (db *DB) AnySignature(anyParams string) (anyReturn error) {\n    //... \n    db.driver.Exec(\"...\")\n    //...\n    return nil\n}\n// Define\npackage driver \n\ntype DB interface{\n    Exec(sql string)error\n}\n\n// Realize\ntype mysql struct {}\nfunc (m *mysql) Exec(sql string) error {return nil}\n\n// Execute\nsql.DB.AnySignature(\"\")\n```\n\u003ca name=\"xSKiY\"\u003e\u003c/a\u003e\n### Actions List\nFor MongoDB, batch processing can be carried out to improve efficiency. As the shielding layer of packaging, we hope to obtain this benefit according to the actual processing of driver. A queue or cache is required to submit a batch operation.\n\n[Batch write operations-MongoDB-CN-Manual](https://docs.mongoing.com/mongodb-crud-operations/bulk-write-operations)\n\n- [x] I think it is enough to undertake Google Go CDK design \n\n\u003ca name=\"g9Zj6\"\u003e\u003c/a\u003e\n### Driver Map \u0026 Opener\nInherited from the Mysql Driver registration method, through the golang standard import_\" github.com/xxx/driver\" different database drivers can be introduced. The principle is to use a global Map.\n\nGo CDK has upgraded the Opener feature. The original custom URL Parsing method is \"mysql\", \"user:password@/dbname\" the features of the new version are blob+file:///dir even \u003capi\u003e+ \u003ctype\u003e+ prefix (e.g. blob+bucket+file:///dir) for Google Cloud SDK, the same URL can provide different functions. However, in our opinion, this function does not have much effect for the time being, so we will block their design. \n\n\u003ca name=\"MrRZi\"\u003e\u003c/a\u003e\n### Dependency Injection wire \nGo CDK use the wire project to inject dependencies to automatically switch the structure of different backend providers to the SDK. Different from the way Dapr accesses different services, Dapr uses the yaml description to determine the different plug-ins that are enabled. \n\nFor example, you need wire.Build() indicates the new function of the driver to be introduced. \n\nIt has little impact on this project and may not be added for the time being. \n\n\u003ca name=\"tUMOU\"\u003e\u003c/a\u003e\n\n### UUID usage\n\nmongoDB, each entry must have a Key, which can be passed through parameters. \n```go\ntype Player struct {\n    ID   interface{} `docstore:\"_id,omitempty\"`\n    Name string\n}\n```\n\nThe simplest is to indicate the_id field directly in the structure. \n\n```go\ndocstore.OpenCollection(context.Background(), \"mongo://my-db/my-coll?id_field=name\")\n```\nYou can also use the URL Parameter in the high-level abstraction. The following example specifies the_ID as the name field of the above-mentioned high-level abstraction, which is used by the underlying layer `mongodocstore.OpenCollection` mapping relationship, will automatically generate mongo official driver type `primitivie.ObjectID `\n\n```go\ncoll, err := mongodocstore.OpenCollection(mcoll, \"id\", nil)\n\ntype IDer struct {\n\tID primitive.ObjectID\n}\n```\n\nyou can also use `mongodocstore.OpenCollectionWithIDFunc` to specify how to generate an ID.\n\n```go\nnameFromDocument := func(doc docstore.Document) interface{} {\n    return primitive.NewObjectID()\n}\ncoll, err := mongodocstore.OpenCollectionWithIDFunc(mcoll, nameFromDocument, nil)\n```\n\n\u003ca name=\"F0eWR\"\u003e\u003c/a\u003e\n## Summary \nWe have completed the access design and understanding of Document Store and can perform basic operations on adding, deleting, modifying, and querying docstores. Next, we will build service applications based on this layer of abstraction. \n\nFor special functions of different docstores, you can add them to docstore to determine whether they are target-driven and change the method of external exposure.\n\n\u003ca name=\"E8DHr\"\u003e\u003c/a\u003e\n## function \n\nthe following shows the functions of the library. \n\n\u003ca name=\"hVYIf\"\u003e\u003c/a\u003e\n### Connect MongoDB\nThe default mongo driver uses MONGO_SERVER_URL link to the server, so you can use code to set it here or directly set it by using environment variables. \n\nthe following meaning is from mongodb://localhost:27017 the link on the server is called `my-db`in the database `my-coll` document. The unique field name of mongo is `name`. \n\n```go\nos.Setenv(\"MONGO_SERVER_URL\", \"mongodb://localhost:27017\")\n\ncoll, err := docstore.OpenCollection(context.Background(), \"mongo://my-db/my-coll?id_field=name\")\ndefer coll.Close()\n```\n\u003ca name=\"HM4A2\"\u003e\u003c/a\u003e\n### Corresponding display structure \n```go\ntype Player struct {\n\tName             string `docstore:\"name,omitempty\"`\n\tScore            int\n\tDocstoreRevision interface{}\n}\n```\n\u003ca name=\"YFPTq\"\u003e\u003c/a\u003e\n### Create \n```go\ncoll.Create(ctx, \u0026Player{Name: \"Pat\", Score: 7}); \n```\n\u003ca name=\"CuHHJ\"\u003e\u003c/a\u003e\n### Get \n```go\ncoll.Get(ctx, \u0026Player{Name: \"Pat\"});\n```\n\u003ca name=\"syvtX\"\u003e\u003c/a\u003e\n### Queries \nyou may need to manually create indexes to complete the query function. \n```go\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\n\t\"gocloud.dev/docstore\"\n)\n\n// Ask for all players with scores at least 20.\niter := coll.Query().Where(\"Score\", \"\u003e=\", 20).OrderBy(\"Score\", docstore.Descending).Get(ctx)\ndefer iter.Stop()\n\n// Query.Get returns an iterator. Call Next on it until io.EOF.\nfor {\n\tvar p Player\n\terr := iter.Next(ctx, \u0026p)\n\tif err == io.EOF {\n\t\tbreak\n\t} else if err != nil {\n\t\treturn err\n\t} else {\n\t\tfmt.Printf(\"%s: %d\\n\", p.Name, p.Score)\n\t}\n}\n```\n\u003ca name=\"zif5K\"\u003e\u003c/a\u003e\n### Update a single field of an Update entry\n```go\npat2 := \u0026Player{Name: \"Pat\"}\nerr := coll.Actions().Update(pat, docstore.Mods{\"Score\": 15}).Get(pat2).Do(ctx)\n```\n\u003ca name=\"VJYOy\"\u003e\u003c/a\u003e\n### Replace \ncompletely replace the entire entry \n```go\ncoll.Replace(ctx, \u0026Player{Name: \"Pat\", Score: 15})\n```\n\u003ca name=\"QjVog\"\u003e\u003c/a\u003e\n### Put \nthe Put function is equivalent to CreateOrUpdate\n```go\ncoll.Put(ctx, \u0026Player{Name: \"Pat\", Score: 15})\n```\n\u003ca name=\"wzyMJ\"\u003e\u003c/a\u003e\n### Delete \n```go\ncoll.Delete(ctx, \u0026Player{Name: \"Pat\", Score: 15})\n```\n\u003ca name=\"wer1V\"\u003e\u003c/a\u003e\n### More examples \n\n- [CLI Sample](https://github.com/google/go-cloud/tree/master/samples/gocdk-docstore)\n- [Order Processor sample](https://gocloud.dev/tutorials/order/)\n- [docstore package examples](https://godoc.org/gocloud.dev/docstore#pkg-examples)\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/Node-Status-Manager":{"title":"Node Status Manager","content":"## Node Status Manager\n\n\u003ca name=\"eQr2o\"\u003e\u003c/a\u003e\n## ReadLink\n- [pkg/kubelet/nodestatus/setters.go](https://sourcegraph.com/github.com/kubernetes/kubernetes/-/blob/pkg/kubelet/nodestatus/setters.go)\n- [/](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e)[pkg /](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/tree/pkg)[kubelet /](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/tree/pkg/kubelet)[kubelet_node_status.go](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet_node_status.go)\n\n\u003ca name=\"HvtiD\"\u003e\u003c/a\u003e\n## Directory Layout\n```go\npkg/kubelet/nodestatus\n |- setters.go\n |- setters_test.go\n```\n\u003ca name=\"ABxjo\"\u003e\u003c/a\u003e\n## Setter\n```go\n// Setter modifies the node in-place, and returns an error if the modification failed.\n// Setters may partially mutate the node before returning an error.\ntype Setter func(node *v1.Node) error\n```\nthe Setter function defines a function that performs operations on the v1.Node object. If an error is returned, the Node object may also be changed. \nFrom the function definition, you can see its usage: use functions to generate different setters for a class of modification of Node objects. In this way, you can modify the state of a Node. \nUse the simplest func GoRuntime() Setter example: \n```go\n// GoRuntime returns a Setter that sets GOOS and GOARCH on the node.\nfunc GoRuntime() Setter {\n\treturn func(node *v1.Node) error {\n\t\tnode.Status.NodeInfo.OperatingSystem = goruntime.GOOS\n\t\tnode.Status.NodeInfo.Architecture = goruntime.GOARCH\n\t\treturn nil\n\t}\n}\n```\nthis mode belongs to the middleware operation mode. You can contact middleware for understanding. \n\u003ca name=\"E3eSp\"\u003e\u003c/a\u003e\n## Setter List\nwe learned the setter mode changed by Node status. Currently, the code contains the following 12 setters:\n- **NodeAddress **returns a Setter that updates address-related information on the node.ï¼šupdates address-related fields, such as IP address and hostname (typically the hostname variable in kubelet). \n- **MachineInfo **returns a Setter that updates machine-related information on the node.ï¼šupdates fields related to host information, such as the maximum number of pods, the number of pods allocated to each core, and the number of resources. \n- **VersionInfo **returns a Setter that updates version-related information on the node.ï¼šcontainerRuntime version, cadvisor version\n- **DaemonEndpoints **returns a Setter that updates the daemon endpoints on the node.\n- **Images **returns a Setter that updates the images on the node.ï¼šupdates image information. \n- **GoRuntime **returns a Setter that sets GOOS and GOARCH on the node.ï¼šGOOS GOARCH information \n- **ReadyCondition** returns a Setter that updates the v1.NodeReady condition on the node.ï¼šdetermines whether the node is in the Ready state from Kubelet fields such as the error return function in the runtimeState. \n- **MemoryPressureCondition **returns a Setter that updates the v1.NodeMemoryPressure condition on the node.\n- **PIDPressureCondition **returns a Setter that updates the v1.NodePIDPressure condition on the node.\n- **DiskPressureCondition **returns a Setter that updates the v1.NodeDiskPressure condition on the node.\n- **VolumesInUse **returns a Setter that updates the volumes in use on the node.\n- **VolumeLimits **returns a Setter that updates the volume limits on the node.\n\n\nSetter çš„å…¥å‚é€šå¸¸æ˜¯ Kubelet ä¸­çš„å­—æ®µï¼Œè‡ªç„¶ä½¿ç”¨æ˜¯é€šè¿‡ Kubelet å»åˆå§‹åŒ–ä½¿ç”¨ã€‚\n\u003ca name=\"uRi9a\"\u003e\u003c/a\u003e\n## Kubelet Node Status\n[/](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e)[pkg /](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/tree/pkg)[kubelet /](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/tree/pkg/kubelet)[kubelet_node_status.go](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet_node_status.go)\n\u003ca name=\"LGGvP\"\u003e\u003c/a\u003e\n###  Setter ä½¿ç”¨å¤„\nafter all setters are initialized in the defaultNodeStatusFuncs function, the function returns a Setter array. \n\n[kubelet_node_status.go? L613](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet_node_status.go?L613)\n\n```go\n// defaultNodeStatusFuncs is a factory that generates the default set of\n// setNodeStatus funcs\nfunc (kl *Kubelet) defaultNodeStatusFuncs() []func(*v1.Node) error {\n\t// if cloud is not nil, we expect the cloud resource sync manager to exist\n\tvar nodeAddressesFunc func() ([]v1.NodeAddress, error)\n\tif kl.cloud != nil {\n\t\tnodeAddressesFunc = kl.cloudResourceSyncManager.NodeAddresses\n\t}\n\tvar validateHostFunc func() error\n\tif kl.appArmorValidator != nil {\n\t\tvalidateHostFunc = kl.appArmorValidator.ValidateHost\n\t}\n\tvar setters []func(n *v1.Node) error\n\tsetters = append(setters,\n\t\tnodestatus.NodeAddress(kl.nodeIPs, kl.nodeIPValidator, kl.hostname, kl.hostnameOverridden, kl.externalCloudProvider, kl.cloud, nodeAddressesFunc),\n\t\tnodestatus.MachineInfo(string(kl.nodeName), kl.maxPods, kl.podsPerCore, kl.GetCachedMachineInfo, kl.containerManager.GetCapacity,\n\t\t\tkl.containerManager.GetDevicePluginResourceCapacity, kl.containerManager.GetNodeAllocatableReservation, kl.recordEvent),\n\t\tnodestatus.VersionInfo(kl.cadvisor.VersionInfo, kl.containerRuntime.Type, kl.containerRuntime.Version),\n\t\tnodestatus.DaemonEndpoints(kl.daemonEndpoints),\n\t\tnodestatus.Images(kl.nodeStatusMaxImages, kl.imageManager.GetImageList),\n\t\tnodestatus.GoRuntime(),\n\t)\n\t// Volume limits\n\tsetters = append(setters, nodestatus.VolumeLimits(kl.volumePluginMgr.ListVolumePluginWithLimits))\n\n\tsetters = append(setters,\n\t\tnodestatus.MemoryPressureCondition(kl.clock.Now, kl.evictionManager.IsUnderMemoryPressure, kl.recordNodeStatusEvent),\n\t\tnodestatus.DiskPressureCondition(kl.clock.Now, kl.evictionManager.IsUnderDiskPressure, kl.recordNodeStatusEvent),\n\t\tnodestatus.PIDPressureCondition(kl.clock.Now, kl.evictionManager.IsUnderPIDPressure, kl.recordNodeStatusEvent),\n\t\tnodestatus.ReadyCondition(kl.clock.Now, kl.runtimeState.runtimeErrors, kl.runtimeState.networkErrors, kl.runtimeState.storageErrors, validateHostFunc, kl.containerManager.Status, kl.shutdownManager.ShutdownStatus, kl.recordNodeStatusEvent),\n\t\tnodestatus.VolumesInUse(kl.volumeManager.ReconcilerStatesHasBeenSynced, kl.volumeManager.GetVolumesInUse),\n\t\t// TODO(mtaufen): I decided not to move this setter for now, since all it does is send an event\n\t\t// and record state back to the Kubelet runtime object. In the future, I'd like to isolate\n\t\t// these side-effects by decoupling the decisions to send events and partial status recording\n\t\t// from the Node setters.\n\t\tkl.recordNodeSchedulableEvent,\n\t)\n\treturn setters\n}\n```\nThe array is assigned to the setNodeStatusFuncs of kubelet.\n```go\n\t// Generating the status funcs should be the last thing we do,\n\t// since this relies on the rest of the Kubelet having been constructed.\n\tklet.setNodeStatusFuncs = klet.defaultNodeStatusFuncs()\n```\n\u003ca name=\"n0m8P\"\u003e\u003c/a\u003e\n## SyncNodeStatus Procedure\nhow do Kubelet use these Kubelet? The core is syncNodeStatus functions.\n\n[kubelet_node_status](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet_node_status.go?L435)\n```go\n// syncNodeStatus should be called periodically from a goroutine.\n// It synchronizes node status to master if there is any change or enough time\n// passed from the last sync, registering the kubelet first if necessary.\nfunc (kl *Kubelet) syncNodeStatus() {\n\tkl.syncNodeStatusMux.Lock()\n\tdefer kl.syncNodeStatusMux.Unlock()\n\n\tif kl.kubeClient == nil || kl.heartbeatClient == nil {\n\t\treturn\n\t}\n\tif kl.registerNode {\n\t\t// This will exit immediately if it doesn't need to do anything.\n\t\tkl.registerWithAPIServer()\n\t}\n\tif err := kl.updateNodeStatus(); err != nil {\n\t\tklog.ErrorS(err, \"Unable to update node status\")\n\t}\n}\n```\nsyncNodeStatus the function is called periodically in goroutine to synchronize the node status to the master.\n\u003ca name=\"bdMgb\"\u003e\u003c/a\u003e\n### å…¥å£ Entry\ncurrently, it is called in three places: \n\n1. [kubelet.go? L1428:26](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet.go?L1428:26)\nin the Run function of the Kubelet, start goroutine for periodic synchronization. \n```go\ngo wait.JitterUntil(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, 0.04, true, wait.NeverStop)\n```\n\n2. [kubelet.go? L2433:7](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet.go?L2433:7)\n: performs one-time synchronization in the fastStatusUpdateOnce function.\n```go\nfunc (kl *Kubelet) fastStatusUpdateOnce() {\n\tfor {\n\t\t...\n        kl.syncNodeStatus()\n        return\n\t}\n}\n```\n\n3. [nodeshutdown_manager_linux.go? L283:11](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/nodeshutdown/nodeshutdown_manager_linux.go?L283:11)\n: it is called in the start() function of nodeshutdownmanager, which is actually a goroutine and is triggered only after the shutdown event is received from the channel.\n```go\nif isShuttingDown {\n    // Update node status and ready condition\n    go m.syncNodeStatus()\n\n    m.processShutdownEvent()\n} \n```\n\n\u003ca name=\"FKaYq\"\u003e\u003c/a\u003e\n### æ³¨å†Œ RegisterWithAPIserver\nif kubelet needs to be registered, a for loop is executed to wait for registration to the APIServer.\n```go\nfor {\n    time.Sleep(step)\n    step = step * 2\n    if step \u003e= 7*time.Second {\n        step = 7 * time.Second\n    }\n\n    // 1. è·å– node å¯¹è±¡åŠå…¶ä¿¡æ¯\n    node, err := kl.initialNode(context.TODO())\n    if err != nil {\n        klog.ErrorS(err, \"Unable to construct v1.Node object for kubelet\")\n        continue\n    }\n\n    klog.InfoS(\"Attempting to register node\", \"node\", klog.KObj(node))\n    // 2. æ³¨å†Œåˆ° APIServer ä¸­å»\n    registered := kl.tryRegisterWithAPIServer(node)\n    if registered {\n        klog.InfoS(\"Successfully registered node\", \"node\", klog.KObj(node))\n        kl.registrationCompleted = true\n        return\n    }\n}\n```\n\n1. node, err := kl.initialNode(context.TODO()) : obtains the node object and its information. \n2. registered := kl.tryRegisterWithAPIServer(node) : Register to APIServer \n\n\u003ca name=\"bj9z5\"\u003e\u003c/a\u003e\n### Use Setter\n[Function tryUpdateNodeStatus (kubelet_node_status.go? L470:20)](https://sourcegraph.com/github.com/kubernetes/kubernetes@d2c5779dadc9ed7a462c36bc280b2f9a200c571e/-/blob/pkg/kubelet/kubelet_node_status.go?L470:20)\n: the processing part of the volumeManager is omitted.\n```go\n// tryUpdateNodeStatus tries to update node status to master if there is any\n// change or enough time passed from the last sync.\nfunc (kl *Kubelet) tryUpdateNodeStatus(tryNumber int) error {\n    originalNode := node.DeepCopy()\n    ...\n\tkl.setNodeStatus(node)\n    ...\n\t// Patch the current status on the API server\n\tupdatedNode, _, err := nodeutil.PatchNodeStatus(kl.heartbeatClient.CoreV1(), types.NodeName(kl.nodeName), originalNode, node)\n    ...\n\treturn nil\n}\n```\nkl.setNodeStatus just traverses all the Setter functions we mentioned just now.\n\n```go\nfunc (kl *Kubelet) setNodeStatus(node *v1.Node) {\n\tfor i, f := range kl.setNodeStatusFuncs {\n\t\tklog.V(5).InfoS(\"Setting node status condition code\", \"position\", i, \"node\", klog.KObj(node))\n\t\tif err := f(node); err != nil {\n\t\t\tklog.ErrorS(err, \"Failed to set some node status fields\", \"node\", klog.KObj(node))\n\t\t}\n\t}\n}\n```\n\u003ca name=\"GWa5D\"\u003e\u003c/a\u003e\n## Conclusion\nwe have learned: \n1. what are the change functions of the Node Status and what rules are followed to sign the function.\n2. how to register a Setter function to a Kubelet. \n3. Kubelet when these setters are called to change the status of a Node. \n\nNext: \n\n1. you can try to add a custom setter function. \n2. Kubernetes code is not as neat as the design. Some todo can be changed after reading this article and code. Try to decouple the code. (You can also find it by searching todo in the code.)\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/Open-Source-History-of-Dapr-project":{"title":"Open Source History of Dapr project","content":"## Open Source History of Dapr project\n\nAt the beginning of this open-source column, I wrote this article to describe the birth and development of open-source projects, express my views on the open-source community and ecology, and share it with you. \n\nSome opinions are out of personal perspective, and there are inevitably some mistakes and mistakes. Please forgive me and correct me. \n\n## Background\nbefore the birth of the Dapr project, I would like to explain the current situation of the Dapr project for readers to understand the project itself. \n\nDapr is a CNCF community-driven open source project with Microsoft as its contributor. Microsoft, according to the author, the first author should be Bai Haishi and Yaron (he is also the author of the Dapr Learning Manual, who proposed OAM and Dapr). \n\nThe work objectives of the Dapr project are described as follows: \n\nDapr is a portable, event-driven runtime that enables any developer to quickly build flexible, stateless, and stateful applications that can run on cloud platforms or edge computing. \nSome community students think Dapr is the next form of the service mesh, and some people also call this runtime software of the new era mecha (mecha), mecha provides distributed capabilities for business applications, just like the operator wearing a mecha, to do what he could not have done.\n\nThe following figure shows Bilgin Ibryam. Multi-Runtime Microservices Architecture \n\n\n![image.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1658032639778/CRnDlZMU-.png align=\"left\")\n\ntherefore, the Dapr project is open-source software that provides distributed capabilities for modern distributed applications. Currently, it is open-source on GitHub and has gained 18.6K stars, which is very popular. \n\n## Birth \nTracing back to open source on GitHub, the first submission was on June 21, 2019, \nthe birth of open-source projects is usually accompanied by the discovery of practical problems. \n\nBefore saying the problems solved by the Dapr project, there is another project that has to be mentioned, Microsoft's OAM(Open Application Model). \n\nThe two projects have been known to the public for 19 years. I remember that the co-sponsor of OAM is Ali. At that time, Kubernetes was very popular, and the problems on the computing scheduling platform were Kubernetes solved by Golang's killer application. \n\nHowever, using Kubernetes puts forward more and higher requirements for Developers, especially its new concept, which covers different APIs and unique working methods. \n\nHow to solve this problem? \n\nAny problem in the field of computer science can be solved by adding an indirect intermediate layer.\n\nIt is believed that smart readers, based on their current knowledge, have already thought that if a new design language can be used as the middle layer to block the similarities and differences of infrastructure developers do not need to pay attention to and focus on business coding, can it be solved? \n\nIn this way, OAM is naturally ready to come out. (If you are concerned about OAM, you can learn about the implementation of this project standard in Alibaba, namely Kubevela project, this project has great potential)\n\nDapr came up with an idea when Bai Haishi and his Israeli colleagues discussed OAM Yaron Schneider. It designed a new programming mode to encapsulate the common functions of the distributed system into Sidecar(Kubernetes concept, description, and business application in the same Pod container) and expose them to developers through HTTP or gRPC (two common transmission modes, which are compatible with most applications). \n\nThe idea is named Distributed Application Runtime, or Dapr for short. [This paragraph is taken from an interview with Bai Haishi, the founder of OAM and DAPR: a simple idea of a 33-year senior programmer -Zhang Shanyou]] \n\nDapr provides several new features to help solve the problems: \n\nthe first is to provide services in the form of Sidecar. In the container orchestration platform, Sidecar provides services in a non-intrusive way. \n\nFor example, Envoy Sidecar acts as a proxy for routing and forwarding. It is independent of major applications and therefore has cross-language features. Users can reuse logic without binding to a programming language, which is especially useful in the microservice era. \n\nThe second is the concept of Building Block, which allows Dapr users to customize different Building blocks, instead of forcing users to use distributed functions provided by Dapr for all functions.\n\n## Open source \n\nAfter talking for so long, I finally talked about the open-source features of the Dapr project. \nThe benefits of open source can be seen in the summary of my other article. This article will not go into detail, but mainly explore the reasons why Dapr needs to open source and provide material examples for everyone to understand the open source operation mode. \n\nDapr can be analyzed from the positioning of its general distributed runtime software, and the standard is its core! \n\nStandards cannot be achieved by one person or a company. It is necessary to strengthen Dapr's influence and promote its designation of standards that are uniformly recognized by everyone. It is the only choice to establish a community of common contributions through open source.\n\nIt is not only a matter of standards. Dapr, as an application in the new era, naturally has many new ideas, which need to be verified. A large number of engineers need to be invested in the verification of the programming mode. \n\nThis part of manpower expenditure and verification cost is extremely large. The continuous development of the project can only be supported by the rapid discussion of design, implementation, and community verification in the form of Community co-construction. \n\nTherefore, human resources are also considered in most open-source projects. \n\nFinally, reach users. \n\nWhen Dapr is a user-oriented project, there are developers who are more enthusiastic than open-source communities. Open-source is the best choice to make Dapr's development closer to users and the wide application of cloud developers that it wants to achieve. \n\nWe recommend two projects to observe the popularity and activity distribution of open-source projects ( Star-History and OSSInsight ), which are Bytebase and PingCap open-source tools. One picture wins thousands of words, and two pictures are attached to show its function. \n\nFigure 1: Star harvest trend of open source Dapr project\n\n![image.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1658032918444/FsLL7iu_d.png align=\"left\")\n\n## Development\nSince the Dapr project is to serve developers, it is natural to investigate the main functions that developers use in the programming and provide them to users as different building blocks. \n\nCurrently, the capabilities it provides include state management, service development, message sending and receiving, publishing and subscription, security information management, Actor mode (originated from the Orleans project in Microsoft's dotnet ecosystem), etc. In the initial form of state management development, concurrent control, version management, and other capabilities are also added. \n\nNow, building blocks such as distributed locks and workflows are gradually added. These new functions and new building blocks are all built by community users' needs.\n\nIt can be seen from this that Dapr's open source strategy has achieved remarkable results. \n\nThe emergence of Dapr also coincides with the wave of XaaS. It reduces the occupation of the edge environment (more than 50 M binary, only 4 M memory is needed during operation), provides edge devices and applications with low capability, flexibly switches between edge environment and cloud, and supports multiple operating environments, which are its excellent sources of competitiveness. \n\nThe development evaluation of an open source project must pay attention to its related ecology. Dapr, as a similar infrastructure project, will discuss two ecosystems. \n\nOne is the ecosystem that supports the Dapr project operation. That is, driven by various Building blocks, their ecology determines which infrastructure Dapr users can apply.\n\nTake PubSub as an example. Common message queue drivers such as Kafka, Redis, NatsStreaming, and Pulsar provide the runtime capability in the publish/subscribe mode. \n\nThe ecosystem in this area is rich and colorful. The core problem is that drivers are contributed to the community by themselves. The code quality and the functions provided during application runtime are uneven. It can be seen that the idea of standardization cannot be easily achieved in the real world. \n\nOne is the Dapr-based project built on it. This ecology can also be reflected in the cases where most companies use Dapr. \n\nThe main users of Dapr started from the founders Microsoft and Ali, and now companies such as Qingyun have participated in the co-construction and produced many projects and practical cases. \n\nTaking Microsoft as an example, users who serve it can easily and painlessly switch the underlying dependencies on the cloud (for example, switching message queues from Rabbitmq to kafka). \nFor example, Alibaba provides a large number of distributed capabilities for function applications in its functional computing platform. \nFor example, Ant Financial has developed a layotto project based on its excellent ServiceMesh development experience, IT has implemented the distributed runtime concept that conforms to its own IT infrastructure (and is open-source).\nFor example, Qingyun's Openfunction is also built using Dapr in the function computing platform.\n\nEven Microsoft has launched a commercial product container app based on Dapr, which allows users to write function-level services. The infrastructure is provided by context. \nDapr provides these services with the choice of only focusing on business code logic. \n\nThe developer ecosystem of open-source projects is an important criterion. The number of issues created, the speed of response, the richness of proposal submission, the degree of the active contributor, the entry and loss of new contributors and core contributors, and other indicators are all important bases for us to evaluate the developer ecosystem. This section can praise ossinsight project, which provides you with query services through the website and provides us with powerful data for evaluating open-source projects. \n\nFigure 2: analysis of open source activities of the Dapr project\n\n![image.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1658033060286/sUkAuPA7c.png align=\"left\")\n\n## Trend \ncompetition trend of domain software: Hot open-source projects actually symbolize the main competition fields in the current industry. PaaS, which took Kubernetes as the core in the past few years, IaaS, which was recently represented by Infra as Code, DevOps and Security, and SaaS and FaaS, which will further compete fiercely in the future, provide better value-added services. Different fields have their own solutions. We can see how to provide more valuable services from the open-source ecosystem. \n\nThe development trend of programmers: modern developers are generally faced with anxiety problems. As programmers, some of our work contents are boring, but with the passion for programming and the pursuit of a career, we can develop various innovative achievements in our daily work, which may not only achieve ourselves but also benefit the world. At the industry level and even at the national level, open source is embraced. Under such a development trend, open source will integrate young programmers as one of the popular cultures. \nMy personal advice is to understand the open source as soon as possible, embrace him, and become a compound talent. The next step for programmers is to explore the open source field. \n\nAnd this article has roughly described the context of the Dapr project. Only from the project ecology of Dapr, we can see the fierce competition in the development of cloud computing. We don't know how many projects are floating and disappearing in the tide, or they never appear in our eyes after a wave of waves. I hope readers can have a deeper understanding and ideas about the software life cycle, especially open-source software.\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/React-Hooks-State-Persistence":{"title":"React Hooks State Persistence","content":"\n\næœ¬æ–‡è®²è¿°å¦‚ä½•åˆ†æè®¾è®¡ é€šè¿‡ React Hooks è¿›è¡Œ State æŒä¹…åŒ–ç®¡ç†\n\n  \n\n## åˆ†æ\n\næ­£å¸¸å‰ç«¯ï¼Œç»„ä»¶ä¸ºç±»æ–‡ä»¶ï¼Œè‡ªå·±ç»´æŒçŠ¶æ€ï¼Œä¸æ˜“å¤ç”¨ã€‚\n\n  \n\né¦–å…ˆæŠŠç»„ä»¶ä¸­çš„ UI å’Œ çŠ¶æ€åˆ†å¼€ï¼Œç”¨ Action è¿æ¥ï¼Œå¦‚ä¸‹å›¾ã€‚\n\n![[blogs/Pasted image 20221011190847.png]]\n\nAction æ˜¯ç®—å­\n\n  \n\n### Function\n\nåˆ™å¯æˆä¸ºä»¥ä¸‹å‡½æ•°\n\n-   UI = `f(S)`\n\n-   çŠ¶æ€é©±åŠ¨ç»„ä»¶é‡æ–°æ¸²æŸ“ UI\n\n-   Scu =`f(Sc, âˆ†)`\n\n-   ç»„ä»¶ä¼šç”¨åˆ°çš„ Scu å’Œ æ›´æ”¹ Sc çš„ âˆ† æ–¹æ³•å†³å®šã€‚\n\n  \n\n#### S\n\næ¯ä¸€ä¸ªç»„ä»¶æœ‰ä»–è‡ªå·±çš„çŠ¶æ€é›† sã€‚\n\n  \n\n##### scu\n\nå³ï¼Œcomponent use ï¼šç»„ä»¶ç”¨åˆ°çš„çŠ¶æ€ï¼Œæ¯”å¦‚è®¡æ•°å™¨ä¸­çš„æ•°å­—\n\næ‰€æœ‰ç»„ä»¶çš„ä½¿ç”¨åˆ° scuÂ å…±åŒç»„æˆä¸€ä¸ªçŠ¶æ€ Scu--æ¸²æŸ“ä¸€ä¸ª UIã€‚\n\n  \n\n##### sc\n\nå³ï¼Œæ”¶åˆ°ç»„ä»¶å½±å“çš„çŠ¶æ€ï¼Œå¦‚ç™»å½•ç»„ä»¶å¯èƒ½æ¯ç™»å½•ä¸€æ¬¡å°±ä¼šå¢åŠ è®¡æ•°å™¨ï¼Œä½†æ˜¯å¯¹äºç™»å½•ç»„ä»¶å¹¶ä¸ä¼šç”¨åˆ°è¿™ä¸ªçŠ¶æ€ï¼Œè™½ç„¶å®ƒä¼šæ›´æ”¹å®ƒã€‚\n\n  \n\n### å…¥å‚\n\n#### âˆ†\n\nè®¾è®¡ State æ¡†æ¶æ—¶ï¼Œè®©æ¯ä¸€ä¸ªç»„ä»¶å£°æ˜ saÂ çŠ¶æ€æ—¶ï¼Œæä¾›ä¸€ä¸ªæ›´æ”¹è‡ªå·±çš„å‡½æ•° maÂ ï¼Œåœ¨ Action äº‹ä»¶æ—¶è°ƒç”¨ç”¨äºæ›´æ”¹ Stateï¼Œè€Œå¤šä¸ª ma çš„é›†åˆä¸º âˆ†ã€‚\n\n  \n\n#### S\n\nSa =`f(S, âˆ†)` ä¸­çš„ S ä½œä¸º f çš„å‚æ•°ä¼ å…¥ï¼Œå› ä¸ºå¹¶ä¸çŸ¥é“ Action ä¼šæ›´æ”¹å“ªäº› State ã€ç”šè‡³ä¸çŸ¥é“æœ‰å“ªäº›ã€‘ï¼Œæ•…æŠŠæ‰€æœ‰ State éƒ½ä½œä¸ºå…¥å‚ã€‚\n\n  \n\n### å±€éƒ¨æ¸²æŸ“\n\næ›´æ”¹çš„çŠ¶æ€é©±åŠ¨ UI æ¸²æŸ“ï¼Œå¦‚æœç›¸åŒå¯ä»¥ä¸æ”¹å˜ã€‚\n\n  \n\nå¦‚ä¸Šæ‰€è¯´ï¼ŒUI ç”±äºå…¥å‚ä¸º S ï¼Œä¼šæ¥æ”¶æ‰€æœ‰çš„ Stateï¼Œç»„ä»¶è‡ªå·±æ ¹æ®è‡ªå·±éœ€è¦çš„ saÂ å˜åŠ¨æ¸²æŸ“ï¼Œè€Œä¸æ˜¯ UI æ ¹æ® S æ”¹åŠ¨åˆ†å‘äº‹ä»¶ã€‚\n\n  \n\nè§‚å¯Ÿ Hooks å¯çŸ¥ï¼Œ`useState()` æ–¹æ³•ä½¿ç”¨`[Object.is](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is#Description)` [æ¯”è¾ƒç®—æ³•](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is#Description)Â æ¥æ¯”è¾ƒ stateã€‚\n\nè€ŒÂ `useEffect()`åˆ™æä¾›é€‰æ‹©è®©å®ƒ [åœ¨åªæœ‰æŸäº›å€¼æ”¹å˜çš„æ—¶å€™](https://zh-hans.reactjs.org/docs/hooks-reference.html#conditionally-firing-an-effect) æ‰æ‰§è¡Œçš„å‚æ•°ã€‚\n\n  \n\n## è®¾è®¡\n\n### å®è™šéƒ¨æ•°å­¦æ¨¡å‹\n\nå®æ•°å¹¶ä¸å®Œå¤‡ï¼Œå¼•å…¥è™šéƒ¨ã€‚\n\n  \n\nè™šæ•°ï¼Œåªéœ€è¦å»æ‰è™šéƒ¨å°±å¯ä»¥è¡¨ç¤ºå®æ•°ã€‚\n\n  \n\nCurry Func ä¹Ÿå¦‚æ­¤ã€‚\n\n  \n\nä»¥ä¸ŠåŒç†ï¼š`f(S,âˆ†)`ä¸­`f(S)` ä»£è¡¨å®æ•°ï¼Œä¸å®Œå¤‡ï¼ŒåŠ å…¥ âˆ† ï¼Œå¯ä»¥è¡¨è¾¾æ‰€æœ‰æƒ…å†µã€‚\n\n  \n\næ›´æ”¹çš„ç»´åº¦ä»ä¸€ç»´çš„ çº¿ æˆä¸ºäº† äºŒç»´çš„å¹³é¢ã€‚\n\n  \n\nå¦ï¼šæ¡†æ¶ä½¿ç”¨çš„`f(S, âˆ†)`è¿˜æ˜¯ä¸€ç»´çš„çº¿ï¼Œä½†å…¶å®æ˜¯è¯¥å¹³é¢ ä»»æ„ä¸€æ¡çº¿ ï¼Œå› ä¸º f(S,âˆ†) å·²ç»ä¸­çš„ âˆ† å’Œ S å·²ç»ç»ç”±ä½¿ç”¨è€…ç¡®å®šï¼Œå³åœ¨å¤šç»´åº¦é€‰æ‹©äº†ä¸€ä¸ªå¹³é¢é™ç»´å®ç°åœ¨ä»£ç ä¸­äº†ã€‚\n\n  \n\n### PersistenceÂ \n\néœ€è¦ä¸€ä¸ªåœ°æ–¹å­˜å‚¨æ•°æ®ï¼Œlocalï¼Œsessionï¼Œremote ç­‰.\n\n  \n\n### Connector\n\nç»„ä»¶å¦‚ä½•æŠŠè§¦å‘çš„äº‹ä»¶åˆ†å‘ç»™ State å¤„ç†ï¼Ÿéœ€è¦é€šä¿¡ã€‚\n\n  \n\nç”±äº js å•çº¿ç¨‹æ¨¡å‹ï¼Œé€‰æ‹©å…±äº«å†…å­˜è®¾è®¡æ–°å¢ä¸€ä¸ª Connector ç”¨äºé€šä¿¡ã€‚\n\n  \n\nç»„ä»¶ Component å¦‚ä½•é€šçŸ¥ State æ”¹åŠ¨ã€‚å…±äº«å†…å­˜ï¼Œé‡‡ç”¨ Connector ä¸­é—´å±‚ã€‚\n\n  \n\n### Action by CurryFunc\n\nState å¦‚ä½•çŸ¥é“æ¡†æ¶ä½¿ç”¨è€…å®šä¹‰çš„ Action æ”¹åŠ¨äº†å“ªäº› State ï¼Ÿå³ä¸çŸ¥é“ âˆ† çš„å…·ä½“å€¼ã€‚é‡‡ç”¨ Curry Func æ»¡è¶³å»¶è¿Ÿæ±‚å€¼çš„éœ€æ±‚ã€‚\n\nä½¿ç”¨ `fg(S){return f(âˆ†)`} ä»£æ›¿Â `f(S,âˆ†)`\n\nState æ¡†æ¶ä½¿ç”¨è€…è‡ªå·±ä½¿ç”¨ `f(âˆ†)` æ³¨å†Œè‡ªå·±çš„çŠ¶æ€æ›´æ”¹ç®—å­ âˆ†ã€‚\n\n  \n\nState æ¡†æ¶å¼€å‘è€…ä½¿ç”¨ `fg(S)` ï¼Œåªç®¡è‡ªå·±ä¼ å…¥æ‰€æœ‰çš„ State å³å¯ã€‚\n\n  \n\nç”±äº React Hooks çš„å­˜åœ¨ï¼Œstate è‡ªå¸¦ä½¿ç”¨ `f(S,âˆ†)` è¿›è¡Œæ›´æ–°çš„åŠŸèƒ½ã€‚æ•…æ¡†æ¶ç•™å‡º useState() æ¥å£ï¼Œè¿”å› `f(âˆ†)` ï¼Œä¾›ä½¿ç”¨è€…è¿›è¡ŒçŠ¶æ€ç®¡ç†ã€‚\n\n  \n\n#### Redux\n\nRedux ä¹Ÿæ˜¯åŸºäºæ­¤å‡½æ•°æ¨¡å‹ï¼Œè€Œåœ¨ Hooks ä¸­å®˜æ–¹å·²ç»ä½¿ç”¨ `useReducer(reducer, initialState)` å®ç°äº†å®ƒã€‚å…¶ä¸­ reducer æ˜¯è®¾å®šå¥½çš„ `f(Sï¼Œâˆ†)` ï¼Œè€Œå®ƒè¿”å› state å’Œ dispatchï¼Œå…¶ä¸­ state å°±æ˜¯ SaÂ è€Œ dispatch å°±æ˜¯ `f(âˆ†)`ã€‚\n\n```js\nfunction useReducer(reducer, initialState) {\n  const [state, setState] = useState(initialState);\n  function dispatch(action) {\n    const nextState = reducer(state, action);\n    setState(nextState);\n  }\n  return [state, dispatch];\n}\n```\n\nåœ¨æˆ‘ä»¬çœ‹æ¥ï¼Œå®ƒä¹Ÿå†…éƒ¨å®ç°äº† Connector çš„ä½œç”¨ã€‚\n\n  \n\n## å®ç°\n\n### Persistence\n\né¦–å…ˆæ˜¯é€šè¿‡ Hooks å®ç°å­˜å‚¨, ä½¿ç”¨ Local Store\n\n```js\nfunction useLocalJSONStore(key, defaultValue) {\n    const [state, setState] = useState(\n      () =\u003e JSON.parse(localStorage.getItem(key)) || defaultValue\n    );\n    useEffect(() =\u003e {\n      localStorage.setItem(key, JSON.stringify(state));\n    }, [key, state]);\n    return [state, setState];\n}\n```\n\n  \n\n#### å­˜å‚¨ä½ç½®\n\nè§£å†³äº†æŒä¹…åŒ–å­˜å‚¨ï¼Œæä¾›å¤–åœ¨çš„çŠ¶æ€ç®¡ç†æ”¯æŒã€‚è€ƒè™‘åˆ°æˆ‘ä»¬ä¼šä½¿ç”¨ Go æ¥åšå‰ç«¯ï¼š\n\n1.  ä½¿ç”¨ Hooks åŠ  sqlite3 åº“æœ¬åœ°å­˜å‚¨\n2.  ä½¿ç”¨ Hooks å’Œ Go é€šä¿¡å®Œæˆ\n\n  \n\n### Connector\n\nä¸ºäº†ä½¿ç”¨ Hooks å®ç°å…¨å±€çš„çŠ¶æ€é€šçŸ¥ã€‚\n\né¦–å…ˆæ˜ç™½ `useState()` è·å–åˆ°çš„ `setState()` ä¼šè§¦å‘å½“å‰ç»„ä»¶çš„æ¸²æŸ“ï¼š[https://zh-hans.reactjs.org/docs/hooks-state.html](https://zh-hans.reactjs.org/docs/hooks-state.html)\n\nConnector è®©ä½¿ç”¨å…¨å±€çŠ¶æ€çš„ç»„ä»¶è®¢é˜…æ¥è¿æ¥ä¸Šå…¨å±€çš„çŠ¶æ€æ›´æ–°ï¼Œå°†è‡ªå·±çš„ `setState()` ä¼ å…¥æ›´æ–°é˜Ÿåˆ—ï¼Œå½“å…¶ä¸­ä»»ä½•ä¸€ä¸ªç»„ä»¶ä½¿ç”¨ `dispatch()` æ›´æ”¹çŠ¶æ€æ—¶ä¼šè§¦å‘è¿™ä¸ªå‘½åç©ºé—´ä¸‹çš„å…¨éƒ¨çŠ¶æ€æ›´æ–°ï¼Œä»è€Œè¾¾åˆ°åˆ·æ–°æ‰€æœ‰çŠ¶æ€ç»„ä»¶çš„ç›®çš„ã€‚\n\n```js\nimport { useEffect } from \"react\"\n\nconst Connector = {}\n\nconst Broadcast = (name, state) =\u003e {\n    if (!Connector[name]) return;\n    Connector[name].forEach(setter =\u003e setter(state))\n}\n\nconst Subscribe = (name, setter) =\u003e {\n    if (!Connector[name]) Connector[name] =[];\n    Connector[name].push(setter)\n}\n\nconst UnSubscribe = (name, setter) =\u003e {\n    if (!Connector[name]) return\n    const index = Connector[name].indexOf(setter)\n    if (index !== -1) Connector[name].splice(index, 1)\n}\n\nconst connect = (name,setState) =\u003e {\n    console.log('connect')\n    useEffect(() =\u003e{\n        Subscribe(name, setState)\n        console.log('subscirbe',name)\n        return () =\u003e {\n            UnSubscribe(name,setState)\n            console.log('unsubscribe',name)\n        }\n    },[])\n}\n```\n  \n\n### useStore\n\nä½¿ç”¨è€…ä½¿ç”¨ `useStore()` æ¥è·å–å…¨å±€çŠ¶æ€å’Œ `dispatch()` å‡½æ•°ã€‚å†…éƒ¨å®ç°å°±æ˜¯ State Hook ï¼Œå¹¶æ‹¿åˆ° `setState()`æ³¨å†Œåˆ°è®¢é˜…åˆ—è¡¨ä¸­ã€‚\n\n```js\nimport {Broadcast,connect} from './Connector'\nimport {useState} from 'react'\n\nexport function useStore(key,value) {\n    const [state,setState] = useState(value)\n    connect(key,setState)\n\n    return [state, (key,value) =\u003e {\n        Broadcast(key,value)\n    }]\n}\n```\n\n  \n\n### ç›®å‰çŠ¶å†µ\n\n  \n\n![](https://cdn.nlark.com/yuque/0/2019/svg/176280/1574064167135-22f14865-31ba-4b6c-a144-0d1315954ec1.svg)\n\n  \n\n## ä½¿ç”¨\n\nä½¿ç”¨ `useStore(key, value)` å³å¯ã€‚\n\n```js\nimport {useStore} from './useStore'\n\nexport function Counter({key,initialCount}) {\n    // const [count, setCount] = useLocalJSONStore(keyname, initialCount);\n    const [state, dispatch] = useStore(key,initialCount)\n    return (\n      \u003c\u003e\n        Count: {state}\n        \u003cbutton onClick={() =\u003e dispatch(keyname,initialCount)}\u003eReset\u003c/button\u003e\n        \u003cbutton onClick={() =\u003e dispatch(keyname,state-1)}\u003e-\u003c/button\u003e\n        \u003cbutton onClick={() =\u003e dispatch(keyname,state+1)}\u003e+\u003c/button\u003e\n      \u003c/\u003e\n    );\n  }\n```\n\n  \n\n![](https://cdn.nlark.com/yuque/0/2019/png/176280/1574063711150-a567cd8c-2117-47ea-8446-02da34624b22.png)\n\n## è¿›é˜¶\n\n-   å¼‚æ­¥çŠ¶æ€\n-   è£…é¥°å™¨","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/Role-of-microservice-framework":{"title":"Role of microservice framework","content":"## Role of microservice framework\n\n## HTTP Channel and GRPC Channel \n\nbefore we begin, let's explore the differences between HTTP and RPC. The reason why gRPC is discussed here is that no one uses common RPC. \n\nHTTP is a common communication method used for business coding, and its popularity is needless to say. As a Web programmer, HTTP Server programming is its core skill. RPC is also indispensable in microservices. \n\nCan programmers who are familiar with one of the encoding quickly get started with the business coding of another transmission method? \n\nAfter all, the business logic is consistent, which seems to be only different in network transmission. \n\nColleagues who have done this know that the differences in business coding are not small. Although the differences are constrained to the transport layer through the abstraction layer during design, there is no framework to block the differences in implementation. Therefore, coding students need to go deep into it and handle it by themselves. \n\nFor example, you need to learn more about envoy and proto files, how to encode requests and return values, and how to use specific protobuf to parse message packets in your business. \n\nThe differences can be shielded at the abstraction level. We still need to write detailed differences in implementation. These are the operations that some programmers can replace with frameworks. \n\n## Top programmers and beginners, beginners, and idiots \n\nthe role of the framework is to make correct coding behavior without thinking.\n\nThere are enough ecological libraries for the current language to help compile various coding types. When lacking, some ecosystems can be transplanted by referring to other languages to reduce the workload. However, not every programmer can do such behavior at any time. \n\nGoogle is a friend. Business Code they often get into trouble because of something they don't know so that no matter how their skills or intelligence are, they can't solve the problem.\n\nIn the business, some coding work will be compared to moving bricks. Programmers are described as manual work to move code from here to there. However, when someone participates in the process, the error probability will also be related to the state of a person.\n\nThrough Murphy's law, we can recognize that errors must occur in these processes. How do reduce personal decisions to ensure high quality and high output of assembly line coding manpower?\n\nIf you want to treat yourself as an idiot coder and leave the error-prone parts to tools, the framework will generate great benefits. \n\n\n\u003e Nothing is built on Stone; Everything is built on sand, but we must build sand as stone.\n\u003e                                 -Jorge Louis Borges \n\n\nthe following are some examples: \n\n- code review: \n\narchitects not only need to formulate process standards, but also need to supervise the implementation. Code review is the major part of the workload. However, there are thousands of people, and code writers have their ideas. There may even be a design-based cohesion function, which is scattered at all levels in implementation, and the review process is even more inefficient. \n\nConstraints can be carried out through the framework, which is also the wisdom of software engineering. By increasing restrictions, standards can be formulated to provide efficiency.\n\n- Best Practices: \n\nbusiness code usually uses simple addition, deletion, modification, query data, and target resources. At the same time, there are some common functional requirements, such as JWT. \n\nThe framework can shield these differences. For example, JWT only has different types of tokens carried by HTTP, and ORM shields the actual data storage software interfaces in the background for addition, deletion, query, modification, and modification. \n\nThis is another wisdom of computer science, solving problems by adding a middle layer. Framework users can switch to different implementations without thinking.\n\nIf the best practices provided by the framework cannot meet the requirements, it is time for the document to show its role. Technical personnel-oriented documentation is useful only when problems occur.\n\n## The dilemma of microservices caused by abstract hierarchy and abstract leakage \n\n\u003e Google software engineering mentions three key differences between programming and software engineering: **time**, **scope**, and **trade-offs**. \n\nHowever, the idea of the framework is beautiful enough, but the realization, in reality, is full of trade-offs and the pursuit of perfection. \n\nEven if the strange requirements of a specific time limit on the business side are excluded. The design cannot be accomplished overnight and a perfect abstract design can be completed.\n\nAbstract leakage refers to the abstraction of implementation details that should be hidden during software development, which inevitably exposes the underlying details and limitations.\n\nNot to mention that a complete system has more than one or two levels. How to make reasonable abstraction and promote it as a standard is a long-term practice and change in many microservice frameworks and coding fields. \n\nAbstraction means unification, while behind the abstraction level, it usually means the actual services with different characteristics. Do you use the union or intersection of these services for abstraction? Whether to consider extended compatibility or functionality.\n\n\u003e For more information, see another article. [Mongo Doc access design](), is practical experience. \n\n\u003e Also The API of Dapr. Many Interfaces of Golang (IO, SQL, and Net) can see abstract practical practices.\n\nFor example, designers will struggle with whether to provide a certain function to the outside, so they have done a lot of work to provide it. However, in terms of function usage, it may be a pseudo requirement or a simple shielding. However, in actual scenarios, it is necessary to have a lower layer of functions, and the abstraction level is still broken down. \n\nAt this point, everyone understands that it falls into specific scenarios and analyzes specific problems. Therefore, a microservice framework that has passed the postgraduate entrance examination for a long time must have solved many problems in the target scenario. \n\n\u003e This reminds me that programmers always pursue new technologies. New microservice frameworks usually have high expectations, hoping that they can completely solve the problems encountered in practice that the old frameworks cannot solve. Finally, expectations often fail. Why can we expect a new untested framework to meet the needs of the technical framework that has been designed and modified many times in practice in specific fields?\n\nBack to our question at the beginning, is there a framework that unifies the HTTP Channel and gRPC Channel, and only needs to write the handler's internal code without paying attention to other work?\n\n In the modern framework, Dapr did accomplish this. \n\nWhat about the abstract cost? \n\nThe field type in the Protobuf is lost, and it is considered a payload. The handler has different self-processing types, which is consistent with HTTP abstraction. \n\nIs it true that such an abstraction layer has just come up with now? If you have a deeper understanding of computer science, you will find that some past ideas shine brilliantly in new scenarios. \n\nTime is the most significant variable (for example, previous programmers needed to deduct bytes. Now, do you still need to care about insufficient memory for personal PC and cloud coding?). \n\n## Summary\nThe above describes the problems related to the microservice framework considered in the experience. Just raising questions is a hooligan. My opinions and suggestions are mentioned a lot in the article. \n\nTo make a summary, it is: \n\nproviding a fool-like automated microservice framework enables programmers to make fewer decisions and make better decisions. \n\nOnly by using the time saved to innovate business links and business models, and not being involved in non-creative work such as environment building, can workers feel the value of innovation and self-achievement.","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/Technician-and-experiencer":{"title":"Technician and experiencer","content":"## Technician and experiencer\n\nWe believe that the experience of the experience is linked to the actual things and actual behaviors, while the technology of the technician symbolizes more general knowledge. \n\nFirst of all, in practical operation, it can be seen that skilled people are inferior to experienced people in all aspects, but they usually do better than inexperienced people. \nBy many views gained from the experience of the universal Judgment (Generic), we believe that technology was born. \n\nGenerally, we think that people with technology have a deeper understanding of this kind of thing, (in short, smarter) because their behaviors will be guided, and their starting point is reason rather than inertia. We also believe that people with technology master the ability to impart theories, but experienced people cannot teach others. \n\nDo you want to judge whether you are good at a certain technology and a master in this field? \n\nwhen you think that you can do something if others ask you but you can only tell the specific situation and specific practices, you are not a wise professor. If the universal judgment you say is not considered dialectically by yourself, you are not a Master of this event. \n\nAccording to this statement, the concept of a Technologist is close to a wise man, and wisdom is also explained as knowledge about the origin and principle of things. Readers can now think about what characteristics people with high IQ have in the concept we are talking about? \n \nfrom the above ideas, it is not surprising that mathematicians call them philosophers or wise men, because this discipline is based on the basic principles (Root) rather than a series of secondary disciplines. \n\nTherefore, the more common the principle is, the more it is regarded as truth. People who think they have mastered the truth tend to be frustrated in the field of new knowledge. \n\nSince the opinions that can be collected correspond to the infinite things, in reality, I am inconvenient to think that the universal principle of a kind of things also lacks the existence of truth because there are infinite kinds. \n\nSo when experts claim to be masters in other fields, I don't fear to think that they are not very good in this field.\n\nThe above metaphysical discussion is not to explore whether the truth exists in a pessimistic way. Instead, I want to express my praise for practical operation from the perspective of reality and the method of getting the so-called twice the result with half the effort by deeply learning the principles of things. \n\nOn the other hand, as programmers, top programmers, and technicians' technologies, they can explain the measurement of the difference in value they create. \n\nIt is not difficult to become an expert in a certain field through practice but based on the viewpoint of experience summary, it will be our goal to put forward universal fragments (.e. creation, design, and the invention of new technologies). ","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/blogs/TokenBucket":{"title":"TokenBucket","content":"## TokenBucket\n\n\n## Overview\n![image.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1657442131915/dUeLDBuYM.png align=\"left\")\n\n\n\n- available per second Limit put tokens into the bucket, or, every time 1/Limit add a token to the second bucket \n- maximum storage in buckets burst tokens. If the bucket is full, the new token will be discarded. \n- when an N is consumed when the data packet of the unit arrives N tokens, and then send the packet \n- if the available token in the bucket is less than N, the packet will be cached or discarded \n\n## token bucket algorithm \n\nthe token bucket algorithm is the most commonly used algorithm in network Traffic Shaping (Traffic Shaping) and Rate Limiting (Rate Limiting). \n\nTypically, the token bucket algorithm is used to control the number of data sent to the network and allow the sending of burst data. \n\n### overview \n\nthis package is based on the Token Bucket algorithm (Token Bucket) to implement throttling, which is very easy to use. RateLimiter is often used to limit the access rate to some physical or logical resources. It supports three methods, \n\n- AllowN() If you can't get it, return it immediately.\n- WaitN() It is temporarily lined up. When the token is sufficient, it may be returned to the position because of the Cancel of Context.\n- ReserveN() Started directly, but the predecessors dug the pit and filled it. The next request will pay the price for this, and wait until the tokens will make up for the air. There is enough token in the barrel.\n\n### Working instance \nassume that one is working RateLimiter \n\n#### allow and wait \nFor a Ratelimiter that generates a token per second, every second without a token, we will add a token 1.\n\n If the Ratelimiter does not use it in 10 seconds, then tokens become 10.0. At this time, a request arrives and requests three tokens, we will serve it from the token in Ratelimiter, tokens to 7.0. After this request, another request comes and requests 10 tokens.\n\n We will from the remaining 7 token cards from RatelimiterFor this request, there are three tokens left, we will get them from the new token produced by Ratelimiter. \n\nWe already know that the Ratelimiter produces 1 new token per second, which means that the above request still requires the three commands required for above request. The card requires it to wait for 3 seconds.\n\n#### reserve\nImagine a Ratelimiter generated a token per second, and now it is not used (in the initial state). If an expensive request requires 100 token cards. If we choose to let this request wait for 100 seconds before allowing it to execute, this is obviously ridiculous. \n\nWhy do we do nothing but just wait for 100 seconds? A better approach is to allow this request to execute immediately (no different from all), and then postpone the subsequent request to the right time point. \n\nWe allow this expensive task to perform immediately and delay the subsequent request for 100 seconds. This strategy is to let the task execute and wait at the same time.\n\n#### About timetoact\nAn important conclusion: Ratelimit does not remember the last request, but the next request allows the time to execute. This can also tell us very straightforwardly that the time interval of reaching the next scheduling time point. \n\nThe Ratelimiter is also very simple: the next scheduling time has passed. The difference between this time and the current time is how long the Ratelimiter has not been used. We will translate this time into tokens.Limit == 1), and just one request per second, then tokens will not grow.\n\n#### burst\nRatelimiter has a barrel capacity that is directly discarded when the request is greater than the capacity of this barrel.\n\nhttps://github.com/golang/time/blob/master/rate/rate.go\n\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-09-28":{"title":"2022-09-28","content":"\n - #todo \n\t* \n\t* \n- #journal \n\t- 17:50 ç¦»ç¾¤çš„ç‰¹å¼‚å­¦ä¹ ä¼šè¿œç¦»å…±è¯†ï¼Œå…±è¯†é€šå¸¸æ˜¯æ­£ç¡®çš„ï¼Œå› æ­¤ç¨€æœ‰çš„æŠ€èƒ½é€‰æ‹©å­˜åœ¨å·¨å¤§çš„é£é™©ï¼Œä¸ºäº†é™ä½é£é™©ï¼Œæˆ‘ä»¬å¿…é¡»ä¿æŒè°¦è™šã€‚\n\t- 18:10 çœ‹åˆ°ä¸€ç¯‡å¾ˆå¥½çš„å…³äºé€‰æ‹©å­¦ä¹ ä»€ä¹ˆæŠ€èƒ½çš„æ–‡ç« ï¼š https://medium.com/accelerated-intelligence/while-most-people-fight-to-learn-in-demand-skills-smart-people-are-secretly-learning-rare-skills-f9b26856c9d6 å­¦ä¹ ç¬”è®°ï¼š[[ä¸ºä»€ä¹ˆå­¦ä¹ ç¨€ç¼ºçš„æŠ€èƒ½]]","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-09-29":{"title":"2022-09-29","content":"\n - #todo \n\t* \n\t* \n- #journal\n- 15:34 æ·»åŠ æµ‹è¯•\u003cbr\u003e\u003cbr\u003e\n- 20:23 memory çœŸå¥½ç”¨ï¼Œå¯ä»¥ç”¨æ¥åæ§½ï¼Œå°±æ˜¯æ²¡æœ‰å‘é€å¿«æ·é”®\n\n- 20:25 æœ€è¿‘éœ€è¦æ€è€ƒå­¦ç‚¹ä»€ä¹ˆä¸œè¥¿ã€‚æŠŠæ˜¨å¤©çš„åšå®¢çœ‹å®Œå§\n- 20:30 å­¦æœ¯æ–‡ç« \u003cbr\u003eæˆ‘é¢†åŸŸä¹‹å¤–çš„å­¦ç§‘ï¼Œå…¶ä»–äººç”šè‡³éƒ½ä¸çŸ¥é“\u003cbr\u003eè®¸å¯ä¸“æœ‰æ•°æ®\u003cbr\u003eä¸å¯èƒ½ä¸ä¼šå…¬å¼€åˆ†äº«æŸäº›è§è§£çš„é¢†åŸŸå†…éƒ¨äººå£«å»ºç«‹æ·±åšçš„å…³ç³»\u003cbr\u003eå¿ƒæ™ºæ¨¡å‹ï¼ˆéš¾ä»¥è¯„ä¼°çš„æŠ½è±¡å€¼ï¼‰\n  è¿™äº›æ‰æ˜¯åº”è¯¥åœ¨æˆ‘ä»¬çš„æ—¥å¸¸å­¦ä¹ ä¸­å»å­¦ä¹ çš„ä¸œè¥¿ï¼Œæ€»ç»“çš„é¢å¾ˆåˆ°ä½ã€‚å› ä¸ºç¨€ç¼ºæ€§ï¼Œæ‰æœ‰æ”¾å¤§çš„ä»·æ ¼ã€‚ ^cff4f1","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-09-30":{"title":"2022-09-30","content":"\n - #todo \n\t* golang devcloud ä½¿ç”¨ minio\n\t* å­¦ä¹ ç¨€æœ‰æŠ€èƒ½çš„è¿›ä¸€æ­¥ç ”ç©¶ï¼Œæ‰¾ä¸€ä¸ªç›®æ ‡ [[ä¸ºä»€ä¹ˆå­¦ä¹ ç¨€ç¼ºçš„æŠ€èƒ½]]\n- #journal ^e61eca","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-10-08":{"title":"2022-10-08","content":"\n- [[buildkit]] \n\t- [é«˜ç­–å†™è¿‡ buildkit çš„ä½¿ç”¨ä½“éªŒ](http://gaocegege.com/Blog/kubernetes/buildkit)ï¼Œåœ¨ä»–çš„ [[envd]] çš„å·¥ä½œä¸­ ^42517f\n\t- æ–° [[Dockerfile]] è¯­æ³•ç‰¹æ€§ï¼šbuildkit å¯ä»¥é€šè¿‡ docker buildx build è§£ææ–°çš„è¯­æ³•ç‰¹æ€§ã€‚from [[2022-10-08#^42517f]] \n\t\t- å¤šæ¬¡ build ä¹‹é—´çš„ç¼“å­˜ `RUN --mount=type=cache,target=/root/.cache/pip pip install ...`\n\t\t- å¤šä½“ç³»æ¶æ„çš„æ”¯æŒ `docker buildx build --platform linux/amd64,linux/arm64 .`\n\t\t- å¤šè¡Œè„šæœ¬ [[Dockerfile å¤šè¡Œè„šæœ¬]] åªå¢åŠ ä¸€ä¸ªæ„å»ºå±‚\n- [[rocksdb]] æ˜¯å•èŠ‚ç‚¹ KV æ•°æ®åº“, è®¾è®¡åŸºäº [[LSMs]] .[[rocksdb]] æ˜¯æ—©æœŸ [[Google]] é¡¹ç›®[[LevelDB]] çš„ä¸€ä¸ªåˆ†æ”¯ã€‚from  [[ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨RocksDBä¸Šåˆ›å»ºCockroachDBé¡¹ç›®ï¼Ÿ]]\n- [demo ç½‘å€](https://postgres-wasm.netlify.app/) [[postgreSQL]] è·‘åœ¨æµè§ˆå™¨é‡Œï¼Œé€šè¿‡ [[wasm]]\n- [[novelai]] ä½¿ç”¨ [[stable diffusion]] ç”Ÿæˆäº†å¤§é‡çš„äºŒæ¬¡å…ƒå›¾ç‰‡ã€‚repo åº“ï¼š [github.com/NovelAI/stable-diffusion](https://github.com/NovelAI/stable-diffusion) ç”¨ [[jupyter nodebook]] å†™çš„\n- è¯•ç”¨ä¸€ä¸‹ [[maigret]] ä¸€ä¸ªé€šè¿‡ç”¨æˆ· id æ”¶é›†å…¨ç½‘è´¦æˆ·æŠ¥å‘Šçš„å·¥å…·","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-10-09":{"title":"2022-10-09","content":"å°è¯•ä½¿ç”¨è½¯ä»¶è¿›è¡Œæ€è·¯çš„æ¢³ç†ï¼Œç°åœ¨æ˜¯ä¸ªäººæ—¶é—´çœ‹æ¿çš„æ¢³ç†ã€‚[[MnicTime]] è¿™ä¸ªè½¯ä»¶æ˜¯å¯ä»¥è®°å½•æ‰€æœ‰çš„è½¯ä»¶çš„æ—¶é—´çš„ã€‚æ‰‹æœº iPhone ä¹Ÿå¯ä»¥è®°å½•è½¯ä»¶ä½¿ç”¨æ—¶é—´ã€‚\nä¸èƒ½åƒä¸Šé¢æµæ°´çº¿è®°å½•ï¼Œä¸ç„¶è·Ÿä¸ä¸Šæ€è·¯ã€‚æ€»ç»“ç„¶åè®°å½•ï¼š\n\nç›®çš„ï¼šéœ€è¦æ‰¾åˆ°å“ªäº›æ˜¯å¯ä»¥ä¼˜åŒ–çš„æ—¶é—´ä¹ æƒ¯ã€‚ é€šè¿‡ç›®å‰å¯¹è‡ªæˆ‘çš„è§‚å¯Ÿï¼š\n1. å„ç§ç¾¤èŠçš„èŠå¤©ï¼Œç„¶åå‘æ¶ˆæ¯ï¼Œæ¶ˆè€—äº†éƒ¨åˆ†æ—¶é—´\n2. æ¶ˆç£¨æ—¶é—´çš„æ“ä½œï¼Œè¿™éƒ¨åˆ†æ—¶é—´åº”è¯¥å±äºå¯ä»¥ä¼˜åŒ–çš„ã€‚\n3. æœ€åæ˜¯å› ä¸ºå¥½å¥‡å¿ƒå»çœ‹æ–‡ç« çš„æ—¶é—´\n\nä¸‰ç±»å¤§æ—¶é—´ä¸­ï¼Œé¦–å…ˆä¼˜åŒ–èŠå¤©æ—¶é—´ï¼Œå»æ‰å¤§éƒ¨åˆ†è¦è¿›å…¥æŸ¥çœ‹çš„ç¾¤èŠå³å¯ï¼Œæ„Ÿè§‰å¾ˆç®€å•å˜›ã€‚\n\n[[ä½¿ç”¨ quartz æ‰˜ç®¡ obsidian åˆ°ç½‘ç»œä¸Š]] \n\n[[æ¸…ç† GIt ä¸­çš„å†å²æ–‡ä»¶]]\n","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-10-10":{"title":"2022-10-10","content":"[[Pricing as Code]] æ˜¯[[Tier]]è¿™ä¸ªäº§å“ä½¿ç”¨çš„ç†å¿µã€‚","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/diary/2022-10-11":{"title":"2022-10-11","content":"","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/hugo-extended":{"title":"hugo-extended","content":"\nhugo å®‰è£…ç½‘å€ï¼š[https://gohugo.io/getting-started/installing/](https://gohugo.io/getting-started/installing/)\n\nwindows æˆ‘ç›´æ¥ä½¿ç”¨äº†å®‰è£…\n```bash\nscoop install hugo-extended\n```","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/hugo-obsidian":{"title":"hugo-obsidian","content":"ä½¿ç”¨ [[Golang]] install åŠŸèƒ½å®‰è£…\n\n```\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/maigret":{"title":"maigret","content":"https://github.com/soxoj/maigret","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/obsidian":{"title":"obsidian","content":"","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null},"/rocksdb":{"title":"rocksdb","content":"","lastmodified":"2022-10-11T11:25:57.63433546Z","tags":null}}